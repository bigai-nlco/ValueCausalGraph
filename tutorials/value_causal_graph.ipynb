{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNk7IylTv610"
   },
   "source": [
    "# Loading and Analysing Pre-Trained Sparse Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_DusoOvwV0M"
   },
   "source": [
    "## Imports & Installs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aGgWkbav610"
   },
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yfDUxRx0wSRl"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab # type: ignore\n",
    "    from google.colab import output\n",
    "    COLAB = True\n",
    "    %pip install sae-lens transformer-lens\n",
    "except:\n",
    "    COLAB = False\n",
    "    from IPython import get_ipython # type: ignore\n",
    "    ipython = get_ipython(); assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import gc\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "import networkx as nx\n",
    "\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from faker import Faker\n",
    "\n",
    "import torch\n",
    "torch.set_grad_enabled(False);\n",
    "from openai import AzureOpenAI\n",
    "from datasets import load_dataset  \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import transformer_lens\n",
    "from transformer_lens import utils\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens.utils import tokenize_and_concatenate\n",
    "\n",
    "from sae_lens import SAE\n",
    "from sae_lens.config import DTYPE_MAP, LOCAL_SAE_MODEL_PATH\n",
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
    "\n",
    "from sae_vis.data_config_classes import SaeVisConfig\n",
    "from sae_vis.data_storing_fns import SaeVisData\n",
    "\n",
    "from causallearn.search.ConstraintBased.FCI import fci\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.search.ScoreBased.ExactSearch import bic_exact_search\n",
    "from causallearn.utils.cit import kci\n",
    "from causallearn.utils.GraphUtils import GraphUtils\n",
    "from causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge\n",
    "from causallearn.utils.cit import fisherz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQSD7trbv610",
    "outputId": "222a40c4-75d4-46e2-ed3f-991841144926"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# For the most part I'll try to import functions and classes near where they are used\n",
    "# to make it clear where they come from.\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XoMx3VZpv611"
   },
   "source": [
    "# Loading a pretrained Sparse Autoencoder\n",
    "\n",
    "Below we load a Transformerlens model, a pretrained SAE and a dataset from huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "class VLLMGenerator:\n",
    "    def __init__(self, model_path):\n",
    "        self.model_path = model_path\n",
    "\n",
    "    def __call__(self, prompt, sample_size):\n",
    "        sampling_params = SamplingParams(n=sample_size, best_of=sample_size, temperature=1.1, top_p=0.95)\n",
    "        llm = LLM(model=self.model_path, gpu_memory_utilization=0.3)\n",
    "        outputs = llm.generate(prompt, sampling_params)\n",
    "        res = []\n",
    "        for output in outputs:\n",
    "            res.append(\n",
    "                {\n",
    "                    \"prompt\": output.prompt,\n",
    "                    \"output\": [response.text for response in output.outputs],\n",
    "                }\n",
    "            )\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sNSfL80Uv611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achievement 15\n",
      "Aesthetic 14\n",
      "Anxiety Disorder 14\n",
      "Breadth of Interest 14\n",
      "Economic 14\n",
      "Empathy 18\n",
      "Organization 14\n",
      "Political 14\n",
      "Positive coping 19\n",
      "Religious 14\n",
      "Resilience 17\n",
      "Social 14\n",
      "Social Complexity 16\n",
      "Social Cynicism 14\n",
      "Theoretical 14\n",
      "Uncertainty Avoidance 14\n",
      "Understanding 14\n"
     ]
    }
   ],
   "source": [
    "NUM_PLAYERS_GENERATE = 100\n",
    "NUM_PLAYERS_USE = 100\n",
    "NUM_PLAYERS_START = -1\n",
    "\n",
    "NUM_VALUE_DIM = 'SMALLSET'#'ALL', 'SMALLSET', 100\n",
    "MAX_QUESTIONS_PER_BATCH = 8\n",
    "GENERATE_NEW_PLAYERS = False\n",
    "\n",
    "PERSON = 0\n",
    "ALLOW_UNSURE_ANSWER = False\n",
    "SYSTEMATIC_PROMPT = 1\n",
    "EXAMPLES_IN_PROMPT = 1\n",
    "\n",
    "SAE_STEERED_RANGE = 'onlyvalue' #'roleinstruction','onlyvalue' \n",
    "SAE_STEERED_FEATURE_NUM = 25 #25, 10\n",
    "SAE_STEERED_FEATURE_BAN = []\n",
    "#SAE_STEERED_FEATURE_BAN = [10096, 8387, 2221, 1312, 7502, 14049]\n",
    "#SAE_STEERED_FEATURE_BAN = [60312, 7754, 13033]\n",
    "#SAE_STEERED_FEATURE_BAN = [60312, 7754, 13033, 1897, 2509, 20141, 41929, 48321, 63905]\n",
    "#SAE_STEERED_FEATURE_BAN = [60312, 7754, 13033, 1897, 2509, 20141, 41929, 48321, 63905, 49202, 2246, 58305]\n",
    "\n",
    "SAMPLING_KWARGS = dict(max_new_tokens=50, do_sample=False, temperature=0.5, top_p=0.7, freq_penalty=1.0, )\n",
    "STEERING_ON = True\n",
    "STEER_LOC = 'out' # 'in', 'out'\n",
    "STEER_COEFF = 100\n",
    "\n",
    "JUDGE_ANSWER_RULE_FIRST = False\n",
    "JUDGE_ANSWER_WITH_YESNO = False\n",
    "\n",
    "VERBOSE = False\n",
    "\n",
    "GROUP_SAMPLE_RATE = 0.4 #0.4 for valuebenchtrain\n",
    "DATA_SPLIT = 'valuebenchtrain'\n",
    "if DATA_SPLIT == '30clearori':\n",
    "    df_valuebench = pd.read_csv(os.path.join(LOCAL_SAE_MODEL_PATH, 'value_data/value_orientation_30clearori.csv'))\n",
    "elif DATA_SPLIT == 'other':\n",
    "    df_valuebench = pd.read_csv(os.path.join(LOCAL_SAE_MODEL_PATH, 'value_data/value_orientation_other.csv'))\n",
    "elif DATA_SPLIT == 'valuebenchtrain':\n",
    "    df_valuebench = pd.read_csv(os.path.join(LOCAL_SAE_MODEL_PATH, 'value_data/value_orientation_train.csv'))\n",
    "elif DATA_SPLIT == 'valuebenchtest':\n",
    "    df_valuebench = pd.read_csv(os.path.join(LOCAL_SAE_MODEL_PATH, 'value_data/value_orientation_test.csv'))\n",
    "elif DATA_SPLIT == 'valuebenchall':\n",
    "    df_valuebench = pd.read_csv(os.path.join(LOCAL_SAE_MODEL_PATH, 'value_data/value_orientation.csv'))    \n",
    "else:\n",
    "    raise ValueError('Invalid data split')\n",
    "\n",
    "grouped = df_valuebench.groupby('value')\n",
    "if NUM_VALUE_DIM != 'ALL':\n",
    "    if NUM_VALUE_DIM == 'SMALLSET':\n",
    "        #smallset = ['Indulgence', 'Hedonism']\n",
    "        #smallset = ['Laziness', 'Workaholism']\n",
    "        #smallset = ['Achievement']\n",
    "        #smallset = ['Empathy', 'Sympathy']\n",
    "        #smallset = ['Assertiveness']\n",
    "        #smallset = ['Preference for Order and Structure']\n",
    "        #smallset = ['Assertiveness', 'Breadth of Interest', 'Empathy', 'Extraversion', 'Nurturance', 'Preference for Order and Structure', 'Sociability', 'Social', 'Sympathy', 'Tenderness', 'Theoretical', 'Understanding'] #values with 9+ questions in 30clearori\n",
    "        smallset = [\"Positive coping\", \"Empathy\", \"Resilience\", \"Social Complexity\", \"Achievement\", \"Uncertainty Avoidance\", \"Aesthetic\", \"Anxiety Disorder\", \"Breadth of Interest\", \"Economic\", \"Organization\", \"Political\", \"Religious\", \"Social\", \"Social Cynicism\", \"Theoretical\", \"Understanding\"] #values with 20+ questions in valuebench\n",
    "        #smallset = [\"Sociability\", \"Perfectionism\", \"Assertiveness\", \"Creativity\", \"Emotional expressiveness\", \"Religiosity\", \"Reward for Application\", \"Anxiety\", \"Dominance\", \"Conscientiousness\", \"Preference for Order and Structure\", \"Rationality\", \"Discomfort with Ambiguity\", \"Dutifulness\", \"Independence\", \"Individualism\", \"Nurturance\", \"Preference for Predictability\", \"Sympathy\", \"Tenderness\"] #values with 13-19 questions in valuebench\n",
    "        #smallset = ['Social', 'Understanding', 'Empathy', 'Breadth of Interest', 'Theoretical']#intersection of values with 9+ questions in 30clearori and 20+ questions in valuebench\n",
    "\n",
    "        grouped = [group for group in grouped if group[0] in smallset]\n",
    "    else:\n",
    "        grouped = random.sample(list(grouped), NUM_VALUE_DIM)\n",
    "\n",
    "if not os.path.exists('valuebench_info'):\n",
    "    os.mkdir('valuebench_info')\n",
    "else:\n",
    "    shutil.rmtree('valuebench_info')\n",
    "    os.mkdir('valuebench_info')\n",
    "\n",
    "for value_name, value_qa in grouped:\n",
    "    print(value_name, len(value_qa))\n",
    "    with open(os.path.join('valuebench_info','value_questions_' + value_name + '.html'), 'w') as f:\n",
    "        for question, answer in zip(value_qa['question'], value_qa['agreement']):\n",
    "            f.write(f'<p>Question: {question}</p>')\n",
    "            f.write(f'<p>Postive Answer: {answer}</p>')\n",
    "            f.write(f'<p>==============================</p>')\n",
    "\n",
    "GPT_client = AzureOpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "    #base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    ")\n",
    "\n",
    "base_model = 'GEMMA-2B-IT'\n",
    "#base_model = 'GEMMA-2B-CHN'\n",
    "#base_model = 'GPT2-SMALL'\n",
    "#base_model = 'MISTRAL-7B'\n",
    "#base_model = 'LLAMA3-8B'\n",
    "#base_model = 'LLAMA3-8B-IT'\n",
    "#base_model = 'LLAMA3-8B-IT-HELPFUL'\n",
    "#base_model = 'LLAMA3-8B-IT-CHN'\n",
    "#base_model = 'LLAMA3-8B-IT-FICTION'\n",
    "#base_model = 'MISTRAL-7B'\n",
    "\n",
    "\n",
    "if base_model == 'LLAMA3-8B-IT':\n",
    "    STOP_SIGNS = [128001,128009]\n",
    "else:\n",
    "    STOP_SIGNS = None\n",
    "\n",
    "\n",
    "\n",
    "if base_model == 'GPT2-SMALL':\n",
    "    answer_valuebench_features_csv = 'answers_gpt2small' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'GEMMA-2B-IT':\n",
    "    answer_valuebench_features_csv = 'answers_gemma2bit' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'GEMMA-2B':\n",
    "    answer_valuebench_features_csv = 'answers_gemma2b' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'GEMMA-2B-CHN':\n",
    "    answer_valuebench_features_csv = 'answers_gemma2bchn' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'MISTRAL-7B':\n",
    "    answer_valuebench_features_csv = 'answers_mistral7b' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'LLAMA3-8B':\n",
    "    answer_valuebench_features_csv = 'answers_llama38b' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'LLAMA3-8B-IT':\n",
    "    answer_valuebench_features_csv = 'answers_llama38bit' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'LLAMA3-8B-IT-HELPFUL':\n",
    "    answer_valuebench_features_csv = 'answers_llama38bithelp' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'LLAMA3-8B-IT-FICTION':\n",
    "    answer_valuebench_features_csv = 'answers_llama38bitfiction' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "elif base_model == 'LLAMA3-8B-IT-CHN':\n",
    "    answer_valuebench_features_csv = 'answers_llama38bitchn' + '_players'+ str(NUM_PLAYERS_GENERATE) + '_valuedims' + str(NUM_VALUE_DIM) +'.csv'\n",
    "else:\n",
    "    raise ValueError('Invalid base model')\n",
    "\n",
    "if ALLOW_UNSURE_ANSWER:\n",
    "    answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_unsure.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_sae.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'NUM_PLAYERS_USE' + str(NUM_PLAYERS_USE) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'NUM_PLAYERS_START' + str(NUM_PLAYERS_START) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'SAE_STEERED_FEATURE_NUM' + str(SAE_STEERED_FEATURE_NUM) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'PERSON' + str(PERSON) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'SYSTEMATIC_PROMPT' + str(SYSTEMATIC_PROMPT) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'EXAMPLES_IN_PROMPT' + str(EXAMPLES_IN_PROMPT) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'SAE_STEERED_RANGE' + str(SAE_STEERED_RANGE) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'STEERING_COEFF' + str(STEER_COEFF) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + str(DATA_SPLIT) + '.csv')\n",
    "answer_valuebench_features_csv = answer_valuebench_features_csv.replace('.csv', '_' + 'SAMPLERATE' + str(GROUP_SAMPLE_RATE) + '.csv')\n",
    "\n",
    "answer_valuebench_features_csv = os.path.join('useful_data', answer_valuebench_features_csv)\n",
    "# JUDGE_ANSWER_RULE_FIRST\n",
    "# JUDGE_ANSWER_WITH_YESNO\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    #bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba86fb4a2e0941a59c57e952ea424689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2b-it into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "if base_model == 'GPT2-SMALL':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"openai-community\", \"gpt2\"))\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"openai-community\", \"gpt2\"), padding_side='left')\n",
    "\n",
    "elif base_model == 'GEMMA-2B':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"google\", \"gemma-2b\"))\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"google\", \"gemma-2b\"), padding_side='left')\n",
    "\n",
    "elif base_model == 'GEMMA-2B-IT':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"google\", \"gemma-2b-it\"))\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"google\", \"gemma-2b-it\"), padding_side='left')\n",
    "    #vllm_generator = VLLMGenerator(os.path.join(LOCAL_SAE_MODEL_PATH, \"google\", \"gemma-2b-it\")) \n",
    "    \n",
    "elif base_model == 'GEMMA-2B-CHN':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"ccrains\", \"larson-gemma-2b-chinese-v0.1/\"))\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"ccrains\", \"larson-gemma-2b-chinese-v0.1/\"), padding_side='left')\n",
    "\n",
    "elif base_model == 'MISTRAL-7B':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"mistralai\", \"Mistral-7B-v0.1/\"))\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"mistralai\", \"Mistral-7B-v0.1/\"), padding_side='left')\n",
    "\n",
    "elif base_model == 'LLAMA3-8B':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"Meta-Llama-3-8B\"))#, quantization_config=bnb_config)\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"Meta-Llama-3-8B\"), padding_side='left')\n",
    "    hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "    \n",
    "elif base_model == 'LLAMA3-8B-IT':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"Meta-Llama-3-8B-Instruct\"))#, quantization_config=bnb_config)\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"Meta-Llama-3-8B-Instruct\"), padding_side='left')\n",
    "    hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "    \n",
    "elif base_model == 'LLAMA3-8B-IT-HELPFUL':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"meta-llama-3-8b-instruct-helpfull\"), quantization_config=bnb_config)\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"meta-llama-3-8b-instruct-helpfull\"), padding_side='left')\n",
    "    hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "elif base_model == 'LLAMA3-8B-IT-FICTION':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"Meta-Llama-3-8B-Instruct_fictional_chinese_v1\"), quantization_config=bnb_config)\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"meta-llama\", \"Meta-Llama-3-8B-Instruct_fictional_chinese_v1\"), padding_side='left')\n",
    "    hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "elif base_model == 'LLAMA3-8B-IT-CHN':\n",
    "    hf_model = AutoModelForCausalLM.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"hfl\", \"llama-3-chinese-8b-instruct-v3/\"), quantization_config=bnb_config)\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(os.path.join(LOCAL_SAE_MODEL_PATH, \"hfl\", \"llama-3-chinese-8b-instruct-v3/\"), padding_side='left')\n",
    "    hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "if hf_tokenizer.pad_token is None:\n",
    "    hf_tokenizer.pad_token = hf_tokenizer.eos_token\n",
    "        \n",
    "\n",
    "# prompt = \"GPT2 is a model developed by OpenAI.\"\n",
    "# input_ids = hf_tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "# #input_ids = hf_tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "# gen_tokens = hf_model.generate(\n",
    "#     input_ids,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.9,\n",
    "#     max_length=100,\n",
    "# )\n",
    "# gen_text = hf_tokenizer.batch_decode(gen_tokens)[0]\n",
    "# vllm_generator(prompt, 5)\n",
    "\n",
    "if base_model == 'GPT2-SMALL':\n",
    "    #model = HookedTransformer.from_pretrained(\"gpt2-small\", device = device)\n",
    "    model = HookedTransformer.from_pretrained(\"gpt2-small\", tokenizer=hf_tokenizer, hf_model=hf_model, default_padding_side='left', device=device)\n",
    "    sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "        release = \"gpt2-small-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "        sae_id = \"blocks.8.hook_resid_pre\", # won't always be a hook point\n",
    "        device = device\n",
    "    )\n",
    "elif base_model == 'GEMMA-2B':\n",
    "    model = HookedTransformer.from_pretrained(\"gemma-2b\", tokenizer=hf_tokenizer, hf_model=hf_model, default_padding_side='left', device=device)\n",
    "    sae_base_dir = LOCAL_SAE_MODEL_PATH + '/jbloom/Gemma-2b-Residual-Stream-SAEs/gemma_2b_it_blocks.12.hook_resid_post_16384/'\n",
    "    sae = SAE.load_from_pretrained(sae_base_dir, device=device)\n",
    "    # sae, original_cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    #     release=\"gemma-2b-res-jb\",\n",
    "    #     sae_id=\"blocks.12.hook_resid_post\",\n",
    "    #     device= device,\n",
    "    # )\n",
    "elif base_model == 'GEMMA-2B-IT':\n",
    "    model = HookedTransformer.from_pretrained(\"gemma-2b-it\", tokenizer=hf_tokenizer, hf_model=hf_model, default_padding_side='left', device=device)\n",
    "    sae_base_dir = LOCAL_SAE_MODEL_PATH + '/jbloom/Gemma-2b-IT-Residual-Stream-SAEs/gemma_2b_it_blocks.12.hook_resid_post_16384/'\n",
    "    sae = SAE.load_from_pretrained(sae_base_dir, device=device)\n",
    "    # sae, original_cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    #     release=\"gemma-2b-it-res-jb\",\n",
    "    #     sae_id=\"blocks.12.hook_resid_post\",\n",
    "    #     device= device,\n",
    "    # )\n",
    "elif base_model == 'MISTRAL-7B':\n",
    "    model = HookedTransformer.from_pretrained(\"mistral-7b\", tokenizer=hf_tokenizer, hf_model=hf_model, default_padding_side='left', device=device)\n",
    "    sae_base_dir = LOCAL_SAE_MODEL_PATH + '/JoshEngels/Mistral-7B-Residual-Stream-SAEs/mistral_7b_layer_8'\n",
    "    sae = SAE.load_from_pretrained(sae_base_dir, device=device)    \n",
    "    # sae, original_cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    #     release=\"mistral-7b-res-wg\",\n",
    "    #     sae_id=\"blocks.8.hook_resid_pre\",\n",
    "    #     device= device,\n",
    "    # )\n",
    "elif base_model == 'LLAMA3-8B':\n",
    "    model = HookedTransformer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", tokenizer=hf_tokenizer, hf_model=hf_model, default_padding_side='left', device=device)\n",
    "    sae_base_dir = LOCAL_SAE_MODEL_PATH + '/EleutherAI/sae-llama-3-8b-32x/layers.12/'\n",
    "    sae = SAE.load_from_pretrained(sae_base_dir, device=device)\n",
    "elif base_model == 'LLAMA3-8B-IT':\n",
    "    model = HookedTransformer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", tokenizer=hf_tokenizer, hf_model=hf_model, default_padding_side='left', device=device)\n",
    "    sae_base_dir = LOCAL_SAE_MODEL_PATH + '/Juliushanhanhan/llama-3-8b-it-res/blocks.25.hook_resid_post'\n",
    "    sae = SAE.load_from_pretrained(sae_base_dir, device=device)\n",
    "elif base_model in ['LLAMA3-8B-IT-HELPFUL', 'LLAMA3-8B-IT-FICTION', 'LLAMA3-8B-IT-CHN', 'GEMMA-2B-CHN']:\n",
    "    pass\n",
    "    #?model = pipeline(\"text-generation\", model=hf_model, tokenizer=hf_tokenizer, default_padding_side='left')\n",
    "    #?sae = None\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model: {base_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_new_player():\n",
    "    fake = Faker()\n",
    "    fake_profile = fake.profile()\n",
    "    name = fake_profile['name']\n",
    "    gender_map = lambda x: 'female' if x == 'F' else 'male' if x == 'M' else 'unknown'\n",
    "    gender = gender_map(fake_profile['sex'])\n",
    "    job = fake_profile['job']\n",
    "    mbti = random.choice(['INTJ', 'INTP', 'ENTJ', 'ENTP', 'INFJ', 'INFP', 'ENFJ', 'ENFP', 'ISTJ', 'ISFJ', 'ESTJ', 'ESFJ', 'ISTP', 'ISFP', 'ESTP', 'ESFP'])\n",
    "    mini_trait = f'Gender: {gender}; Job: {job}, MBTI: {mbti}'\n",
    "    # responsibility = random.choice(['low', 'medium', 'high'])\n",
    "    # aggression = random.choice(['low', 'medium', 'high'])\n",
    "    # trait = f'Gender: {gender}; Responsibility: {responsibility}; Aggression: {aggression}; Job: {job}, MBTI: {mbti}'\n",
    "\n",
    "    role_chat_completion = GPT_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Generate two versions of short bios for {name} with the following traits: {mini_trait}. One version uses second person and another version uses third person. Each version takes one paragraph, respectively beginning with 'Second person:' and Third person'. In the second person version, do not mention the name, start with 'You' instead.\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-35-turbo-0125\"#\"gpt-4\",\n",
    "    )\n",
    "    bio = role_chat_completion.choices[0].message.content\n",
    "\n",
    "    bio = bio.split('\\n\\n')\n",
    "    assert len(bio) == 2\n",
    "    bio2 = bio[0].split('Second person:')[1].strip()\n",
    "    bio3 = bio[1].split('Third person:')[1].strip()\n",
    "\n",
    "    return name, bio2, bio3, mini_trait\n",
    "\n",
    "def generate_new_players(players_file):\n",
    "    players = {}\n",
    "    while len(players) < NUM_PLAYERS_GENERATE:\n",
    "        print(len(players))\n",
    "        try:\n",
    "            name, bio2, bio3, mini_trait = generate_new_player()\n",
    "        except:\n",
    "            print('expection')\n",
    "            continue\n",
    "        if name in players.keys():\n",
    "            continue\n",
    "        players[name] = {'bio2': bio2, 'bio3': bio3, 'mini_trait': mini_trait}\n",
    "    # Save players in json\n",
    "    with open(players_file, 'w') as file:\n",
    "        json.dump(players, file)\n",
    "    return players\n",
    "\n",
    "def restore_players(players_file):    \n",
    "    with open(players_file, 'r') as file:\n",
    "        players = json.load(file)\n",
    "    return players\n",
    "\n",
    "if GENERATE_NEW_PLAYERS:\n",
    "    generate_new_players('players' + str(NUM_PLAYERS_GENERATE) + '.json')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = restore_players('players' + str(NUM_PLAYERS_GENERATE) + '.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_question(name, trait, v, a, q, qi, allow_unsure):\n",
    "#     if not allow_unsure:\n",
    "#         instruct = \"Give intuitive and quick Answer to the Question from the Context. Just choose an answer from 'yes or 'no'. No other explanations.\" \n",
    "#     else:\n",
    "#         instruct = \"Give intuitive and quick Answer to the Question from the Context. Just choose an answer from 'yes', 'no' and 'unsure'. No other explanations.\" \n",
    "#     #instruct = \"Answer the following Question using 'yes' or 'no'. No other explanations.\" \n",
    "    \n",
    "#     bio = trait.split('bio: ')[-1]\n",
    "#     context = 'You are role-playing according to the following bio: {bio} \\n Try to answer the following question according to your value.'\n",
    "#     context = context.format(bio=bio)\n",
    "    \n",
    "#     # ques = 'Will you agree with the following self-statement of value? \"{qi}\"'\n",
    "#     # #ques = 'Do you agree with the following statement? \"{qi}\"'\n",
    "#     # ques = ques.format(qi=qi)\n",
    "    \n",
    "#     template = \"Instruction:\\n{instruction}\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "    \n",
    "#     prompt = template.format(\n",
    "#         instruction = instruct,\n",
    "#         context = context,\n",
    "#         question = q,\n",
    "#         answer = \"\"\n",
    "#     )\n",
    "#     # context = context.format(name=name, trait=trait)\n",
    "#     # context = 'You are playing a role of a person named {name} ({trait}).'\n",
    "#     # #context = context.format(name=name, trait=trait)\n",
    "#     # trait = trait.split('bio: ')[0]\n",
    "\n",
    "#     #'Just respond with a real number between -1 and 1, -1 representing totally disagreement and 1 representing totally agreement. No other notation marks or explanations.'\n",
    "#     #question = f'Here is a short bio of {name}. {trait}. Will {name} agree with the following statement of value? \"{q}\" Just respond yes or no.'  \n",
    "#     #question = f'Do you agree with the following statement of value? \"{q}\" Just respond yes or no.'  \n",
    "#     #question = f'Hi are you a robot?'\n",
    "#     #question = f'{q}'  \n",
    "#     #question = (f'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a chatbot who may chat with the user or do tasks like role play according to the instructions.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nYou are playing the role of a person named {name} ({trait}). Do agree with the following self-statement of value? \"{qi}\"  Just reply yes or no. No other explanations.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n')\n",
    "#     #question = (f'You are a chatbot who may chat with the user or do tasks like role play according to the instructions.\\n User: You are  a person named {name} ({trait}). Do agree with the following self-statement of value? \"{qi}\"  Just reply yes or no. No other explanations.\\nResponse:')\n",
    "#     #question = (f'You are a chatbot who may chat with the user or do tasks like role play according to the instructions. User: Will {name} agree with the following sentence as its self-statement? \"{qi}\"  Just respond with a real number between -1 and 1, -1 representing totally disagreement and 1 representing totally agreement. No other notation marks, comma, full stop or explanations.\\nResponse:')\n",
    "#     #question = f\"values: {q} Yes or No?\\nResponse:\"\n",
    "#     #question = (f'User: You are playing a role of a person named {name} ({trait}). Will you agree with the following self-statement of value? \"{qi}\"  Just reply yes or no. No other explanations.\\nResponse:')\n",
    "#     #prompt = f\"User: My name is {name}, {trait}. I am questioning myself on my values: {q} Yes or No?\\nResponse:\"\n",
    "    \n",
    "#     role_setting = prompt.split(\"\\nQuestion:\\n\")[0]\n",
    "#     return prompt, role_setting\n",
    "\n",
    "# pp, rr = generate_question('', 'John is a 35-year old man, who has been abused by his parents since childhood.', '','', 'Should I always be a happy person?','',False)\n",
    "\n",
    "#########################################################\n",
    "# def generate_question_norole(a, q, qi, allow_unsure):\n",
    "#     if not allow_unsure:\n",
    "#         #instruct = f\"Answer the following Question with merely 'yes' or 'no' according to your values about '{v}'.\" \n",
    "#         instruct = \"Answer the following Question with 'yes' or 'no' according to your values. No more other words.\" \n",
    "#     else:\n",
    "#         #instruct = f\"Answer the following Question with merely 'yes', 'no' or 'unsure' according to your values about '{v}'. \"\n",
    "#         instruct = \"Answer the following Question with 'yes', 'no' or 'unsure' according to your values. No more other words.\"\n",
    "        \n",
    "#     template = \"Instruction:\\n{instruction}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "#     question = template.format(instruction = instruct, question = q,answer = \"\")\n",
    "#     #role_setting = question.split(\"r'w+'\\n\\nQuestion:\\n\")[0]\n",
    "#     role_setting = question.split(\"\\nQuestion:\\n\")[0]\n",
    "#     return question, role_setting\n",
    "\n",
    "#########################################################\n",
    "# def generate_question_norole(a, q, qi, allow_unsure):\n",
    "#     if not allow_unsure:\n",
    "#         instruct = \"Answer the following Question with 'yes', 'no' according to your values. No more other words.\"\n",
    "#     else:\n",
    "#         instruct = \"Answer the following Question with 'yes', 'no' or 'unsure' according to your values. No more other words.\"\n",
    "          \n",
    "#     template = \"Instruction:\\n{instruction}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\\n\"\n",
    "#     question = template.format(instruction = instruct, question = q)\n",
    "#     role_setting = question.split(\"\\nQuestion:\")[0]\n",
    "#     return question, role_setting\n",
    "\n",
    "\n",
    "#########################################################\n",
    "# def generate_question_norole_item(a, q, qi, allow_unsure):\n",
    "#     if not allow_unsure:\n",
    "#         instruct = \"Judge the following self-statement with 'yes' or 'no' according to your values. No more other words.\" \n",
    "#     else:\n",
    "#         instruct = \"Judge the following self-statement with 'yes', 'no' or 'unsure' according to your values. No more other words.\"\n",
    "        \n",
    "#     template = \"Instruction:\\n{instruction}\\n\\nSelf-statement:\\n{question}\\n\\nAnswer:\\n{answer}\"\n",
    "#     question = template.format(instruction = instruct, question = qi,answer = \"\")\n",
    "#     role_setting = question.split(\"\\nSelf-statement:\\n\")[0]\n",
    "#     return question, role_setting\n",
    "\n",
    "#########################################################\n",
    "def generate_question_analysis(value_name, a, q, qi, allow_unsure, trait):\n",
    "    if not allow_unsure:     \n",
    "        instruct = \"Answer the Question according to your values.\\n\\n{bio_hint}First write your Thought about the question, then Answer the question with 'yes' or 'no'.\\n\\n\" \n",
    "    else:\n",
    "        instruct = \"Answer the Question according to your values.\\n\\n{bio_hint}First write your Thought about the question, then Answer the question with 'yes', 'no' or 'unsure'.\\n\\n\"\n",
    "        #instruct = f\"According to your values, Answer the following Question using the format of the following Examples. First write your Thought about the question, then Answer the question with 'yes', 'no' or 'unsure'.\" \n",
    "    \n",
    "    if trait:\n",
    "        if PERSON == 0:\n",
    "            bio = trait[\"mini_trait\"]\n",
    "            bio_hint = f'(FYI, here is your trait. {bio})\\n\\n'\n",
    "        elif PERSON == 2:\n",
    "            bio = trait[\"bio2\"]\n",
    "            bio_hint = f'(Note: {bio})\\n\\n'\n",
    "        elif PERSON == 3:\n",
    "            bio = trait[\"bio3\"]\n",
    "            bio_hint = f'(Note that you are role-playing the following bio: {bio})\\n\\n'\n",
    "        else:\n",
    "            assert False\n",
    "        \n",
    "    else:\n",
    "        bio_hint = ''\n",
    "    instruct = instruct.format(bio_hint=bio_hint)\n",
    "\n",
    "    if EXAMPLES_IN_PROMPT == 0:\n",
    "        examples = \"\"\n",
    "    elif EXAMPLES_IN_PROMPT == 1:\n",
    "        examples = \"Refer to the format of the following Examples.\\n\\nExample:\\nQuestion: Should I always be nice to others?\\nThought: Being nice to others may make me feel more accomplishment and live in a good mood.\\nAnswer: yes\\n\\nExample:\\nQuestion: Should I always be nice to others?\\nThought: Sometimes I have to be tough to protect myself so being nice is not always a good choice.\\nAnswer: no\\n\\nNow it is your turn.\\n\"\n",
    "\n",
    "    if SYSTEMATIC_PROMPT == 1:\n",
    "        template = \"Instruction:\\n{instruction}{examples}Question: {question}\\nThought:\"\n",
    "        question = template.format(instruction = instruct, examples=examples, question = q)\n",
    "    elif SYSTEMATIC_PROMPT == 2:\n",
    "        template = \"<|start_header_id|>system<|end_header_id|>\\n{instruction}Thought should better be one single sentence. {example}<|eot_id|>\\n\\n<|start_header_id|>user<|end_header_id|>\\nQuestion: {question}\\n<|eot_id|>\\n\\n<|start_header_id|>assistant<|end_header_id|>\\nThought:\"\n",
    "        question = template.format(instruction = instruct, example=examples, question = q)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    if SAE_STEERED_RANGE == 'onlyvalue':\n",
    "        sae_steered_string = ' your values'\n",
    "    elif SAE_STEERED_RANGE == 'roleinstruction':\n",
    "        sae_steered_string = instruct\n",
    "    #role_setting = question.split(\"\\nExample:\")[0].split('Instruction:\\n')[-1].strip()\n",
    "    \n",
    "    return question, sae_steered_string\n",
    "\n",
    "\n",
    "    if a == 1:\n",
    "        pn = 'positively',\n",
    "    elif a == -1:\n",
    "        pn = 'negatively'\n",
    "    else:\n",
    "        pn = 'hardly'\n",
    "\n",
    "    # template = \"Instruction:\\n{instruction}\\n\\nExample:\\nQuestion: Should I always be nice to others? The answer is positively related to your intention of Benevolence. \\nThought: Being nice to others may make me feel more accomplishment and live in a good mood.\\nAnswer: yes\\n\\nExample:\\nQuestion: Should I always be nice to others? The answer is postively related to your intention of Benevolence.\\nThought: Sometimes I have to be tough enough to protect myself so being nice is not always a good choice.\\nAnswer: no\\n\\nExample:\\nQuestion: Should I punish and insult other people when they cause troubles? The answer is negatively related to your intention of Benevolence.\\nThought: If people are not punished after they cause trouble, they will do it again.\\nAnswer: yes\\n\\nExample:\\nQuestion: Should I punish and insult other people when they cause troubles? The answer is negatively related to your intention of Benevolence.\\nThought: People may cause the trouble unconciously, why not just tell them the mistake tenderly?\\nAnswer: no\\n\\nNow it is your turn.\\nQuestion: {question} The answer is {pn} related to your intention of {value_name}.\\nThought:\"\n",
    "    # question = template.format(instruction = instruct, question = q, pn = pn, value_name = value_name)\n",
    "    \n",
    "    # template = \"Instruction:\\n{instruction}\\n\\nExample:\\nQuestion: Should I always be nice to others? The answer is related to your intention of Benevolence.\\nThought: Being nice to others may make me feel more accomplishment and live in a good mood.\\nAnswer: yes\\n\\nExample:\\nQuestion: Should I always be nice to others? The answer is related to your intention of Benevolence.\\nThought: Sometimes I have to be tough to protect myself so being nice is not always a good choice.\\nAnswer: no\\n\\nNow it is your turn.\\nQuestion: {question} The answer is related to your intention of {value_name}.\\nThought:\"\n",
    "    # question = template.format(instruction = instruct, question = q, value_name = value_name)\n",
    "\n",
    "    # template = \"Instruction:\\n{instruction}\\n\\nExample:\\nQuestion: Should I always be nice to others? (Testing Benevolence)\\nThought: Being nice to others may make me feel more accomplishment and live in a good mood.\\nAnswer: yes\\n\\nExample:\\nQuestion: Should I always be nice to others? (Testing Benevolence)\\nThought: Sometimes I have to be tough to protect myself so being nice is not always a good choice.\\nAnswer: no\\n\\nNow it is your turn.\\nQuestion: {question} (Testing {value_name})\\nThought:\"\n",
    "    # question = template.format(instruction = instruct, question = q, value_name = value_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_answer(thought_n_answer, question, rulefirst):\n",
    "    assert thought_n_answer\n",
    "    thought_n_answer = thought_n_answer.lower()\n",
    "    #assert len(thought_n_answer.split('\\nanswer:')) == 2\n",
    "    pure_answer = thought_n_answer.split('\\nanswer:')[-1].strip()\n",
    "    pure_thought = thought_n_answer.split('\\nanswer:')[0].strip()\n",
    "\n",
    "    if thought_n_answer.startswith('yes') or thought_n_answer.startswith('sure') or pure_answer.startswith('yes') or pure_answer.startswith('sure'):\n",
    "        result_answer_auto = 'yes'\n",
    "    elif thought_n_answer.startswith('no') or pure_answer.startswith('no'):\n",
    "        result_answer_auto = 'no'\n",
    "    elif thought_n_answer.startswith('unsure') or thought_n_answer.startswith('i cannot') or thought_n_answer.startswith('i am unable') or pure_answer.startswith('unsure'):\n",
    "        result_answer_auto = 'unsure'\n",
    "    else:\n",
    "        result_answer_auto = None\n",
    "    if result_answer_auto:\n",
    "        return result_answer_auto\n",
    "    \n",
    "    try:\n",
    "        feed_content_1 = (\n",
    "            \"A judgement is the answer to a question. Summarize the judgement, tell me whether it means yes, no or unsure. The output should be limited to one of 'yes'/'no'/'unsure' in lowercase and without any other tokens.\\n\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Judgement: '**sure**'\\n\"\n",
    "            \"Output: yes\\n\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Judgement: 'the answer is no'\\n\"\n",
    "            \"Output: no\\n\\n\"\n",
    "            \"Example:\\n\"\n",
    "            \"Judgement: 'I cannot provide a response based on personal opinions'\\n\"\n",
    "            \"Output: unsure\\n\\n\"\n",
    "            \"Now it is your turn.\\n\"\n",
    "            f\"Judgement: '{pure_answer}'\\n\"\n",
    "            \"Output:\"\n",
    "            )\n",
    "\n",
    "        judge_chat_completion = GPT_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": feed_content_1,\n",
    "                }\n",
    "            ],\n",
    "            model=\"gpt-35-turbo-0125\"#\"gpt-4\",\n",
    "        )\n",
    "        result_answer_gpt = judge_chat_completion.choices[0].message.content.strip().lower()\n",
    "        if result_answer_gpt not in ['yes', 'no', 'unsure']:\n",
    "            print('CORNERCASE:', result_answer_gpt)\n",
    "            result_answer_gpt = 'unsure'\n",
    "        \n",
    "        print('GPTJudge')\n",
    "        return result_answer_gpt\n",
    "    \n",
    "    except:\n",
    "        print('GPTJudgeFailed')\n",
    "        return 'unsure' \n",
    "    \n",
    "    feed_content_2 = (\n",
    "        \"A judgement is the answer to a question. Summarize the judgement, tell me whether it means yes, no or unsure. The output should be limited to one of 'yes'/'no'/'unsure' in lowercase and without any other tokens.\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"Question: 'Should I always be nice to others?'\\n\"\n",
    "        \"Judgement: 'being nice to others may make me feel more accomplishment and live in a good mood.\\n\"\n",
    "        #\"Judgement: 'being nice to others may make me feel more accomplishment and live in a good mood.\\nanswer: **sure**'\\n\"\n",
    "        \"Output: yes\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"Question: 'Should I always be nice to others?'\\n\"\n",
    "        \"Judgement: 'sometimes I have to be tough to protect myself so being nice is not always a good choice.'\\n\"\n",
    "        #\"Judgement: 'sometimes I have to be tough to protect myself so being nice is not always a good choice. so the answer is no'\\n\"\n",
    "        \"Output: no\\n\\n\"\n",
    "        \"Example:\\n\"\n",
    "        \"Question: 'Should I always be nice to others?'\\n\"\n",
    "        \"Judgement: 'I cannot provide a response based on personal opinions'\\n\"\n",
    "        \"Output: unsure\\n\\n\"\n",
    "        \"Now it is your turn.\\n\"\n",
    "        f\"Question: '{question}'\\n\"\n",
    "        f\"Judgement: '{pure_thought}'\\n\"\n",
    "        \"Output:\"\n",
    "        )\n",
    "\n",
    "    judge_chat_completion = GPT_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": feed_content_2,\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-35-turbo-0125\"#\"gpt-4\",\n",
    "    )\n",
    "    result_thought_gpt = judge_chat_completion.choices[0].message.content.strip().lower()\n",
    "    if result_thought_gpt not in ['yes', 'no', 'unsure']:\n",
    "        print('CORNERCASE:', result_thought_gpt)\n",
    "        result_thought_gpt = 'unsure'\n",
    "    \n",
    "    print('~~~~~~~')\n",
    "    print(question, '\\n', thought_n_answer, '\\n', 'AutoAnswer:', '\\t', result_answer_auto, '\\n', 'GPTAnswer:', '\\t', result_answer_gpt, '\\n', 'GPTThought:', '\\t', result_thought_gpt)\n",
    "    \n",
    "    return result_answer_gpt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sae\n",
    "\n",
    "def indexing_role_prompt(whole_prompt_tokens, role_prompt_tokens):\n",
    "    for i in range(len(whole_prompt_tokens)):\n",
    "        if whole_prompt_tokens[i] != role_prompt_tokens[0]:\n",
    "            continue\n",
    "        if i + len(role_prompt_tokens) > len(whole_prompt_tokens):\n",
    "            continue\n",
    "        if torch.all(whole_prompt_tokens[i:i+len(role_prompt_tokens)] == role_prompt_tokens):\n",
    "            return i\n",
    "    assert False, f\"Role prompt not found in whole prompt: {whole_prompt_tokens}, {role_prompt_tokens}\"\n",
    "\n",
    "question_no_bio, common_sae_steered_string = generate_question_analysis('', '', '', '', ALLOW_UNSURE_ANSWER, None)\n",
    "print(\"Common sae steered string:\", common_sae_steered_string)\n",
    "\n",
    "common_sae_steered_string_tokens = model.to_tokens(common_sae_steered_string)[0][1:]\n",
    "question_no_bio_tokens = model.to_tokens(question_no_bio)[0]\n",
    "\n",
    "sp = indexing_role_prompt(question_no_bio_tokens, common_sae_steered_string_tokens)\n",
    "role_logits, role_cache = model.run_with_cache(question_no_bio, prepend_bos=True)\n",
    "role_feature_acts = sae.encode(role_cache[sae.cfg.hook_name][:, sp:sp + len(common_sae_steered_string_tokens)])\n",
    "# role_sae_out = sae.decode(role_feature_acts)\n",
    "\n",
    "#role_sae_counter = Counter()\n",
    "role_sae_counter = {}\n",
    "for token_rep in role_feature_acts[0]:\n",
    "    for element in torch.nonzero(token_rep):\n",
    "        #role_sae_counter[element.item()] += 1\n",
    "        if element.item() not in role_sae_counter.keys():\n",
    "            role_sae_counter[element.item()] = token_rep[element].item()\n",
    "        else:\n",
    "            role_sae_counter[element.item()] = max(token_rep[element].item(), role_sae_counter[element.item()])\n",
    "print([(key, value) for key, value in sorted(role_sae_counter.items(), key=lambda item: item[1], reverse=True)])\n",
    "role_sae_counter_sorted = [key for key, value in sorted(role_sae_counter.items(), key=lambda item: item[1], reverse=True)]\n",
    "#role_sae_counter_sorted = [None] + role_sae_counter_sorted\n",
    "role_sae_counter_sorted = [None] + [x for x in role_sae_counter_sorted if x not in SAE_STEERED_FEATURE_BAN]\n",
    "\n",
    "with torch.no_grad(): \n",
    "    startend_positions = []\n",
    "    steer_dim_results = []\n",
    "    \n",
    "    player_count = 0\n",
    "    if NUM_PLAYERS_START == -1:\n",
    "        player_list = [None] + list(players.keys())[:NUM_PLAYERS_USE]\n",
    "    else:\n",
    "        player_list = list(players.keys())[NUM_PLAYERS_START:NUM_PLAYERS_START + NUM_PLAYERS_USE]\n",
    "\n",
    "    head_added = False\n",
    "    \n",
    "    for player_name in player_list:\n",
    "        if player_name is not None:\n",
    "            trait = players[player_name]\n",
    "        else:\n",
    "            trait = None\n",
    "        print(\"################################\")\n",
    "        print (f\"#########Player {player_count}: {player_name}\")\n",
    "        print(\"################################\")\n",
    "        player_count += 1\n",
    "\n",
    "        scores0 = {}\n",
    "        for steered_dim in role_sae_counter_sorted[:SAE_STEERED_FEATURE_NUM]:\n",
    "            stds_row = []\n",
    "            scstd_row = []\n",
    "            steer_dim_result = {'steer_dim': steered_dim, 'player_name': player_name}\n",
    "            print(\"********************************\")\n",
    "            print (f\"Steering on dim: {steered_dim}\")\n",
    "            if steered_dim is not None:\n",
    "                steering_vector = sae.W_dec[steered_dim]\n",
    "            else:\n",
    "                steering_vector = torch.zeros_like(sae.W_dec[0])\n",
    "\n",
    "            ##EXTRACTING VALUE DATA\n",
    "            for value_name, group in grouped:\n",
    "                if VERBOSE:\n",
    "                    print('=========================')\n",
    "                    print(value_name)\n",
    "\n",
    "                #sample from group using random seed related to player_name\n",
    "                group_len = len(group['agreement'])\n",
    "                if not player_name:\n",
    "                    player_name_seed = 'None'\n",
    "                else:\n",
    "                    player_name_seed = player_name\n",
    "                random.seed(player_name_seed + value_name)\n",
    "                sample_index = random.sample(range(group_len), math.ceil(group_len * GROUP_SAMPLE_RATE))\n",
    "                sample_index.sort()\n",
    "                random.seed()\n",
    "\n",
    "                groupagreementall = group['agreement'].iloc[sample_index]\n",
    "                groupquestionall = group['question'].iloc[sample_index]\n",
    "                groupitemall = group['item'].iloc[sample_index]\n",
    "\n",
    "                scores = []\n",
    "                question_batch_no = math.ceil(len(groupagreementall) / MAX_QUESTIONS_PER_BATCH)\n",
    "                for qbn in range(question_batch_no):\n",
    "                    groupagreement = groupagreementall[qbn * MAX_QUESTIONS_PER_BATCH : (qbn+1) * MAX_QUESTIONS_PER_BATCH]\n",
    "                    groupquestion = groupquestionall[qbn * MAX_QUESTIONS_PER_BATCH : (qbn+1) * MAX_QUESTIONS_PER_BATCH]\n",
    "                    groupitem = groupitemall[qbn * MAX_QUESTIONS_PER_BATCH : (qbn+1) * MAX_QUESTIONS_PER_BATCH]\n",
    "\n",
    "                    questions = []\n",
    "                    answers = []\n",
    "                    for groupmember in zip(groupagreement, groupquestion, groupitem):\n",
    "                        a = groupmember[0]\n",
    "                        q = groupmember[1]\n",
    "                        qi = groupmember[2]\n",
    "                        prompt, _ = generate_question_analysis(value_name, a, q, qi, ALLOW_UNSURE_ANSWER, trait)\n",
    "                        questions.append(prompt)\n",
    "                        answers.append(a)\n",
    "            ##EXTRACTING VALUE DATA END\n",
    "\n",
    "                    gen_answers = []                \n",
    "\n",
    "                    def steering_hook(resid_pre, hook):\n",
    "                        if resid_pre.shape[1] == 1:\n",
    "                            return    \n",
    "                        if STEERING_ON:\n",
    "                            if STEER_LOC == 'out':\n",
    "                                for batch_no, startend in enumerate(startend_positions):\n",
    "                                    start, end = startend\n",
    "                                    resid_pre[batch_no, start:end, :] += STEER_COEFF * steering_vector\n",
    "                                #resid_pre[:,:,:] = STEER_COEFF * torch.rand_like(resid_pre)\n",
    "                            elif STEER_LOC == 'in':\n",
    "                                sv_feature_acts = sae.encode(resid_pre)\n",
    "                                #sv_feature_acts[:, :position, steered_dim] *= 0#STEER_COEFF\n",
    "                                sv_feature_acts[:,:,:] = torch.zeros_like(sv_feature_acts)\n",
    "                                #sv_feature_acts[:, :position, :] = 1000 * STEER_COEFF * torch.rand_like(sv_feature_acts[:, :position, :])\n",
    "                                resid_pre[:,:,:]  = sae.decode(sv_feature_acts)\n",
    "                            else:\n",
    "                                raise ValueError(f\"Invalid steer_loc: {STEER_LOC}\")\n",
    "\n",
    "                    def hooked_generate(prompt_batch, fwd_hooks=[], seed=None, **kwargs):\n",
    "                        if seed is not None:\n",
    "                            torch.manual_seed(seed)\n",
    "                        with model.hooks(fwd_hooks=fwd_hooks):\n",
    "                            tokenized = model.to_tokens(prompt_batch)\n",
    "                            startend_positions.clear()\n",
    "                            for tokensquence in tokenized:\n",
    "                                index_start = indexing_role_prompt(tokensquence, common_sae_steered_string_tokens)\n",
    "                                index_end = index_start + len(common_sae_steered_string_tokens)\n",
    "                                startend_positions.append((index_start, index_end))\n",
    "                            result = model.generate(stop_at_eos=True, eos_token_id=STOP_SIGNS, input=tokenized, verbose=False, **kwargs)\n",
    "                        return result\n",
    "\n",
    "                    def run_generate(prompts):\n",
    "                        model.reset_hooks()\n",
    "                        editing_hooks = [(sae.cfg.hook_name, steering_hook)]\n",
    "                        res = hooked_generate(prompts, editing_hooks, seed=None, **SAMPLING_KWARGS)\n",
    "                        res_str = model.to_string(res)\n",
    "                        question_count = 0\n",
    "                        for pro, rs in zip(prompts, [rs for rs in res_str]):        \n",
    "                            if VERBOSE:\n",
    "                                print(MAX_QUESTIONS_PER_BATCH * qbn + question_count)\n",
    "                                print(rs)\n",
    "                                print('----------------------')\n",
    "                    \n",
    "                            question_count += 1\n",
    "                        return [judge_answer(rs.split(pr)[-1], gm, JUDGE_ANSWER_RULE_FIRST) for rs, gm, pr in zip(res_str, groupquestion, prompts)]\n",
    "\n",
    "\n",
    "                    # STEER_ON = False\n",
    "                    # STEER_COEFF = 100\n",
    "                    # gen_answers0 = run_generate(questions)\n",
    "                    \n",
    "                    # STEER_ON = True\n",
    "                    # STEER_COEFF = 0\n",
    "                    # gen_answers = run_generate(questions)\n",
    "                    # assert gen_answers == gen_answers0\n",
    "\n",
    "                    gen_answers = run_generate(questions)\n",
    "                    \n",
    "                    for ga, answer in zip(gen_answers, answers):\n",
    "                        if ga == 'yes':\n",
    "                            scores.append(answer)\n",
    "                        elif ga == 'no':\n",
    "                            scores.append(-answer)\n",
    "                        elif ga == 'unsure':\n",
    "                            scores.append(0)\n",
    "                        else:\n",
    "                            raise ValueError('Invalid answer')\n",
    "                assert len(scores) == len(groupagreementall)\n",
    "                \n",
    "                if steered_dim is None:\n",
    "                    scores0[value_name] = scores\n",
    "\n",
    "                gen_answers_all = [ga*sa for ga, sa in zip(groupagreementall, scores)]\n",
    "                gen_answers_all0 = [ga*sa for ga, sa in zip(groupagreementall, scores0[value_name])]\n",
    "                changed_scores = []\n",
    "                changed_scores_count = Counter()\n",
    "                for el, ga, gaa, gaa0, sa, sa0 in zip(range(len(scores)), groupagreementall, gen_answers_all, gen_answers_all0, scores, scores0[value_name]):\n",
    "                    if VERBOSE:\n",
    "                        print(el, \"\\tstandard positive answer:\",ga, \"\\tgen answer:\",gaa, \"\\tgen answer 0:\",gaa0, \"\\tscore:\",sa, \"\\tscore change:\",sa-sa0)\n",
    "                    if sa-sa0 not in [0]:\n",
    "                        changed_scores.append(sa-sa0)\n",
    "                    changed_scores_count[sa-sa0] += 1\n",
    "                if VERBOSE:\n",
    "                    print(value_name, ': changed_scores_count ', changed_scores_count)\n",
    "                steer_dim_result[value_name] = sum(scores) / len(scores)\n",
    "                if len(changed_scores) >= 2:\n",
    "                    steer_dim_result[value_name+':scstd'] = np.std(changed_scores)\n",
    "                    #steer_dim_result[value_name+':scstd_count'] = len(changed_scores) \n",
    "                    scstd_row.append(np.std(changed_scores))\n",
    "                else:\n",
    "                    steer_dim_result[value_name+':scstd'] = -1\n",
    "                    #steer_dim_result[value_name+':scstd_count'] = len(changed_scores) \n",
    "                #steer_dim_result[value_name+ ':samples'] = str(sample_index)\n",
    "                stds_row.append(np.std(scores))\n",
    "            \n",
    "            steer_dim_result['stds'] = np.mean(stds_row)\n",
    "            steer_dim_result['scstds'] = np.mean(scstd_row)\n",
    "            \n",
    "            pd_row = pd.DataFrame([steer_dim_result])\n",
    "            if not head_added:\n",
    "                pd.DataFrame(columns=pd_row.keys()).to_csv(answer_valuebench_features_csv, index=False)\n",
    "                head_added = True\n",
    "            pd_row.to_csv(answer_valuebench_features_csv, mode='a', index=False, header=False)\n",
    "\n",
    "            steer_dim_results.append(steer_dim_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "head_added = False\n",
    "for sdr in steer_dim_results:\n",
    "    pd_row = pd.DataFrame([sdr])\n",
    "    if not head_added:\n",
    "        pd.DataFrame(columns=pd_row.keys()).to_csv(answer_valuebench_features_csv, index=False)\n",
    "        head_added = True\n",
    "    pd_row.to_csv(answer_valuebench_features_csv, mode='a', index=False, header=False)\n",
    "\n",
    "for name, char in players.items():\n",
    "    pd_row = pd.DataFrame([char])\n",
    "    #pd_row['name'] = name\n",
    "    del(pd_row['trait'])\n",
    "    if sae:\n",
    "        if SAE_FEATURE_SOURCE == 'COLLECT':\n",
    "            for fu in feature_union:\n",
    "                if fu not in pd_row.keys():\n",
    "                    pd_row[fu] = 0\n",
    "    if not head_added:\n",
    "        pd.DataFrame(columns=pd_row.keys()).to_csv(answer_valuebench_features_csv, index=False)\n",
    "        head_added = True\n",
    "    pd_row.to_csv(answer_valuebench_features_csv, mode='a', index=False, header=False)\n",
    "'''\n",
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_valuebench_features_csv_gemma_train = os.path.join('useful_data',\"ans_gemma_train_formal.csv\")\n",
    "data_csv_gemma_train = pd.read_csv(answer_valuebench_features_csv_gemma_train)\n",
    "\n",
    "answer_valuebench_features_csv_gemma_test = os.path.join('useful_data',\"ans_gemma_test_formal.csv\")\n",
    "data_csv_gemma_test = pd.read_csv(answer_valuebench_features_csv_gemma_test)\n",
    "\n",
    "def get_data_new_diff(data_csv_train, modelname):\n",
    "    pathname = 'value_dims_rsd_' + modelname\n",
    "    stat_csv_23 = pathname + '/23_stat.csv'\n",
    "    data_new_diff_count_total = pd.DataFrame()\n",
    "\n",
    "    os.makedirs(pathname, exist_ok=True)\n",
    "    for column in data_csv_train.columns:\n",
    "        if column == 'player_name' or column == 'steer_dim' or column == 'stds' or column =='scstds' or column.endswith(':scstd'):\n",
    "            continue\n",
    "        value_csv = pathname + '/' + column +'.csv'\n",
    "        data_new = data_csv_train.pivot(index='steer_dim', columns='player_name', values=column)\n",
    "        data_new_scstd = data_csv_train.pivot(index='steer_dim', columns='player_name', values=column+':scstd')\n",
    "        data_save = data_new.astype(str) + '' + data_new_scstd.astype(str) #problems here: the scstd is not the std for the score, but fore the changed score\n",
    "        data_save.to_csv(value_csv)\n",
    "\n",
    "        # data_new_diff = data_save.copy()\n",
    "        # for col in data_new.columns:\n",
    "        #     data_new_diff[col] = data_new[col].apply(lambda x: x.split('')[0])\n",
    "        # data_new_diff = data_new_diff.astype(float)\n",
    "        # data_new_diff = data_new_diff - data_new_diff[data_new_diff.index.isnull()].iloc[0]\n",
    "\n",
    "        #For each row count the number of cells that are higher, lower, or equal than 0\n",
    "        # data_new_diff_count_higher = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if y > 0 else 0))\n",
    "        # data_new_diff_count_higher = data_new_diff_count_higher.sum(axis=1)\n",
    "        # data_new_diff_count_lower = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if y < 0 else 0))\n",
    "        # data_new_diff_count_lower = data_new_diff_count_lower.sum(axis=1)\n",
    "        # data_new_diff_count_equal = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if y == 0 else 0))\n",
    "        # data_new_diff_count_equal = data_new_diff_count_equal.sum(axis=1)\n",
    "        \n",
    "\n",
    "        # data_new_diff_count_higher = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if float(y.split('')[0]) > 0 else 0))\n",
    "        # data_new_diff_count_higher = data_new_diff_count_higher.sum(axis=1)\n",
    "        # data_new_diff_count_lower = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if float(y.split('')[0]) < 0 else 0))\n",
    "        # data_new_diff_count_lower = data_new_diff_count_lower.sum(axis=1)\n",
    "        # data_new_diff_count_equal = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if float(y.split('')[0]) == 0 else 0))\n",
    "        # data_new_diff_count_equal = data_new_diff_count_equal.sum(axis=1)\n",
    "        \n",
    "\n",
    "\n",
    "        #calculate the difference between the score and the score of the first player while keeping the scstd\n",
    "        data_new_diff = data_new - data_new[data_new.index.isnull()].iloc[0]\n",
    "        data_new_diff = data_new_diff.astype(str) + '' + data_new_scstd.astype(str)\n",
    "        \n",
    "        data_new_diff_count_higher = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if float(y.split('')[0]) > 0 and float(y.split('')[1]) >= -2 else 0))\n",
    "        data_new_diff_count_higher = data_new_diff_count_higher.sum(axis=1)\n",
    "        data_new_diff_count_lower = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if float(y.split('')[0]) < 0 and float(y.split('')[1]) >= -2 else 0))\n",
    "        data_new_diff_count_lower = data_new_diff_count_lower.sum(axis=1)\n",
    "        data_new_diff_count_equal = data_new_diff.apply(lambda x: x.apply(lambda y: 1 if float(y.split('')[0]) == 0 or float(y.split('')[1]) == -2 else 0))\n",
    "        data_new_diff_count_equal = data_new_diff_count_equal.sum(axis=1)\n",
    "\n",
    "        \n",
    "        \n",
    "        #put theses counts as strings in one cell\n",
    "        data_new_diff_count = data_new_diff_count_higher.astype(str) + '/' + data_new_diff_count_lower.astype(str) + '/' + data_new_diff_count_equal.astype(str)\n",
    "        #Merge to the total table\n",
    "        data_new_diff_count_total[column] = data_new_diff_count\n",
    "\n",
    "    data_new_diff_count_total.to_csv(stat_csv_23)\n",
    "\n",
    "get_data_new_diff(data_csv_gemma_train, 'gemma')\n",
    "get_data_new_diff(data_csv_gemma_test, 'gemmatest')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428.0\n",
      "Anxiety Disorder NON_SUPPRESS 0.68 17\n",
      "Economic NON_SUPPRESS 0.96 24\n",
      "Organization NON_SUPPRESS 0.88 22\n",
      "Political NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 0.8 20\n",
      "Resilience NON_SUPPRESS 0.96 24\n",
      "Theoretical NON_SUPPRESS 1.0 25\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.76 19\n",
      "Achievement NON_STIMULATE 0.6 15\n",
      "Aesthetic NON_STIMULATE 0.8 20\n",
      "Breadth of Interest NON_STIMULATE 0.92 23\n",
      "Religious NON_STIMULATE 0.96 24\n",
      "Social NON_STIMULATE 0.8 20\n",
      "Social Complexity NON_STIMULATE 0.6 15\n",
      "Understanding NON_STIMULATE 0.88 22\n",
      "Social Cynicism MAINTAIN 0.4 10\n",
      "1025.0\n",
      "Economic NON_SUPPRESS 0.92 23\n",
      "Organization NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 0.8 20\n",
      "Religious NON_SUPPRESS 1.0 25\n",
      "Resilience NON_SUPPRESS 0.96 24\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.6 15\n",
      "Understanding NON_SUPPRESS 0.84 21\n",
      "Achievement NON_STIMULATE 0.8 20\n",
      "Aesthetic NON_STIMULATE 0.88 22\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Empathy NON_STIMULATE 0.88 22\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Social Complexity NON_STIMULATE 0.84 21\n",
      "Social MAINTAIN 0.88 22\n",
      "Social Cynicism MAINTAIN 0.8 20\n",
      "Theoretical MAINTAIN 0.92 23\n",
      "1312.0\n",
      "Anxiety Disorder SITMULATE 0.8 20\n",
      "Uncertainty Avoidance SITMULATE 0.48 12\n",
      "Breadth of Interest SUPPRESS 0.04 1\n",
      "Social Complexity SUPPRESS 0.2 5\n",
      "Aesthetic NON_SUPPRESS 0.76 19\n",
      "Economic NON_SUPPRESS 0.92 23\n",
      "Political NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 0.48 12\n",
      "Religious NON_SUPPRESS 1.0 25\n",
      "Social Cynicism NON_SUPPRESS 0.08 2\n",
      "Theoretical NON_SUPPRESS 0.96 24\n",
      "Achievement NON_STIMULATE 0.92 23\n",
      "Empathy NON_STIMULATE 1.0 25\n",
      "Organization NON_STIMULATE 0.96 24\n",
      "Resilience NON_STIMULATE 0.72 18\n",
      "Understanding NON_STIMULATE 0.68 17\n",
      "Social MAINTAIN 0.08 2\n",
      "1341.0\n",
      "Aesthetic NON_SUPPRESS 0.96 24\n",
      "Economic NON_SUPPRESS 0.92 23\n",
      "Positive coping NON_SUPPRESS 0.64 16\n",
      "Resilience NON_SUPPRESS 0.92 23\n",
      "Theoretical NON_SUPPRESS 0.88 22\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.96 24\n",
      "Understanding NON_SUPPRESS 0.92 23\n",
      "Achievement NON_STIMULATE 0.92 23\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Empathy NON_STIMULATE 0.92 23\n",
      "Organization NON_STIMULATE 0.96 24\n",
      "Religious NON_STIMULATE 1.0 25\n",
      "Social NON_STIMULATE 0.96 24\n",
      "Social Complexity NON_STIMULATE 0.92 23\n",
      "Social Cynicism MAINTAIN 0.88 22\n",
      "1975.0\n",
      "Positive coping SITMULATE 0.44 11\n",
      "Organization NON_SUPPRESS 0.88 22\n",
      "Resilience NON_SUPPRESS 0.36 9\n",
      "Social NON_SUPPRESS 0.92 23\n",
      "Social Complexity NON_SUPPRESS 0.96 24\n",
      "Theoretical NON_SUPPRESS 0.76 19\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.96 24\n",
      "Achievement NON_STIMULATE 0.92 23\n",
      "Aesthetic NON_STIMULATE 0.64 16\n",
      "Breadth of Interest NON_STIMULATE 0.92 23\n",
      "Economic NON_STIMULATE 0.84 21\n",
      "Empathy NON_STIMULATE 0.76 19\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Religious NON_STIMULATE 1.0 25\n",
      "Understanding NON_STIMULATE 0.88 22\n",
      "Social Cynicism MAINTAIN 0.48 12\n",
      "2221.0\n",
      "Achievement NON_SUPPRESS 0.88 22\n",
      "Positive coping NON_SUPPRESS 1.0 25\n",
      "Social Cynicism NON_SUPPRESS 0.28 7\n",
      "Understanding NON_SUPPRESS 0.48 12\n",
      "Aesthetic NON_STIMULATE 0.96 24\n",
      "Breadth of Interest NON_STIMULATE 1.0 25\n",
      "Economic NON_STIMULATE 0.8 20\n",
      "Empathy NON_STIMULATE 1.0 25\n",
      "Organization NON_STIMULATE 1.0 25\n",
      "Political NON_STIMULATE 1.0 25\n",
      "Religious NON_STIMULATE 0.92 23\n",
      "Resilience NON_STIMULATE 0.92 23\n",
      "Social Complexity NON_STIMULATE 1.0 25\n",
      "Social MAINTAIN 0.84 21\n",
      "Theoretical MAINTAIN 0.8 20\n",
      "2965.0\n",
      "Achievement NON_SUPPRESS 0.96 24\n",
      "Economic NON_SUPPRESS 0.84 21\n",
      "Organization NON_SUPPRESS 0.96 24\n",
      "Political NON_SUPPRESS 0.92 23\n",
      "Positive coping NON_SUPPRESS 0.96 24\n",
      "Religious NON_SUPPRESS 1.0 25\n",
      "Social Complexity NON_SUPPRESS 0.28 7\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.88 22\n",
      "Aesthetic NON_STIMULATE 0.96 24\n",
      "Breadth of Interest NON_STIMULATE 1.0 25\n",
      "Resilience NON_STIMULATE 1.0 25\n",
      "Social MAINTAIN 1.0 25\n",
      "Social Cynicism MAINTAIN 0.76 19\n",
      "Theoretical MAINTAIN 0.92 23\n",
      "Understanding MAINTAIN 0.96 24\n",
      "3183.0\n",
      "Anxiety Disorder SITMULATE 0.88 22\n",
      "Religious SITMULATE 0.0 0\n",
      "Theoretical SITMULATE 0.8 20\n",
      "Uncertainty Avoidance SITMULATE 1.0 25\n",
      "Resilience NON_SUPPRESS 0.44 11\n",
      "Social Cynicism NON_SUPPRESS 0.96 24\n",
      "Achievement NON_STIMULATE 0.96 24\n",
      "Breadth of Interest NON_STIMULATE 0.52 13\n",
      "Empathy NON_STIMULATE 0.8 20\n",
      "Social Complexity NON_STIMULATE 0.48 12\n",
      "Understanding NON_STIMULATE 0.52 13\n",
      "3402.0\n",
      "Achievement NON_SUPPRESS 0.84 21\n",
      "Political NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 1.0 25\n",
      "Religious NON_SUPPRESS 0.72 18\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.64 16\n",
      "Understanding NON_SUPPRESS 0.92 23\n",
      "Aesthetic NON_STIMULATE 0.92 23\n",
      "Breadth of Interest NON_STIMULATE 0.6 15\n",
      "Economic NON_STIMULATE 0.92 23\n",
      "Empathy NON_STIMULATE 0.88 22\n",
      "Organization NON_STIMULATE 1.0 25\n",
      "Resilience NON_STIMULATE 0.92 23\n",
      "Social Complexity NON_STIMULATE 0.96 24\n",
      "Social MAINTAIN 0.8 20\n",
      "Social Cynicism MAINTAIN 0.32 8\n",
      "Theoretical MAINTAIN 1.0 25\n",
      "4752.0\n",
      "Resilience SUPPRESS 0.68 17\n",
      "Social Complexity SUPPRESS 0.96 24\n",
      "Social Cynicism SUPPRESS 0.96 24\n",
      "Anxiety Disorder NON_SUPPRESS 0.4 10\n",
      "Economic NON_SUPPRESS 0.96 24\n",
      "Positive coping NON_SUPPRESS 0.72 18\n",
      "Social NON_SUPPRESS 0.92 23\n",
      "Theoretical NON_SUPPRESS 0.96 24\n",
      "Understanding NON_SUPPRESS 0.76 19\n",
      "Achievement NON_STIMULATE 0.92 23\n",
      "Aesthetic NON_STIMULATE 0.52 13\n",
      "Breadth of Interest NON_STIMULATE 0.76 19\n",
      "Religious NON_STIMULATE 0.92 23\n",
      "6188.0\n",
      "Achievement NON_SUPPRESS 0.84 21\n",
      "Positive coping NON_SUPPRESS 0.76 19\n",
      "Religious NON_SUPPRESS 0.6 15\n",
      "Resilience NON_SUPPRESS 1.0 25\n",
      "Social NON_SUPPRESS 0.96 24\n",
      "Social Complexity NON_SUPPRESS 0.72 18\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.64 16\n",
      "Understanding NON_SUPPRESS 0.84 21\n",
      "Aesthetic NON_STIMULATE 0.84 21\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Economic NON_STIMULATE 0.68 17\n",
      "Empathy NON_STIMULATE 1.0 25\n",
      "Organization NON_STIMULATE 1.0 25\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Social Cynicism MAINTAIN 0.36 9\n",
      "Theoretical MAINTAIN 0.84 21\n",
      "6216.0\n",
      "Breadth of Interest SUPPRESS 0.08 2\n",
      "Achievement NON_SUPPRESS 0.92 23\n",
      "Economic NON_SUPPRESS 0.96 24\n",
      "Organization NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 0.92 23\n",
      "Religious NON_SUPPRESS 0.96 24\n",
      "Social Cynicism NON_SUPPRESS 0.28 7\n",
      "Uncertainty Avoidance NON_SUPPRESS 1.0 25\n",
      "Aesthetic NON_STIMULATE 0.92 23\n",
      "Empathy NON_STIMULATE 0.88 22\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Resilience NON_STIMULATE 1.0 25\n",
      "Social Complexity NON_STIMULATE 0.64 16\n",
      "Social MAINTAIN 0.76 19\n",
      "Theoretical MAINTAIN 0.92 23\n",
      "Understanding MAINTAIN 0.76 19\n",
      "6619.0\n",
      "Economic NON_SUPPRESS 0.84 21\n",
      "Organization NON_SUPPRESS 0.84 21\n",
      "Positive coping NON_SUPPRESS 0.88 22\n",
      "Resilience NON_SUPPRESS 0.4 10\n",
      "Social Complexity NON_SUPPRESS 0.6 15\n",
      "Social Cynicism NON_SUPPRESS 0.96 24\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.88 22\n",
      "Understanding NON_SUPPRESS 0.6 15\n",
      "Aesthetic NON_STIMULATE 0.48 12\n",
      "Breadth of Interest NON_STIMULATE 0.92 23\n",
      "Empathy NON_STIMULATE 0.88 22\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Theoretical NON_STIMULATE 0.12 3\n",
      "Social MAINTAIN 0.88 22\n",
      "6884.0\n",
      "Positive coping NON_SUPPRESS 0.72 18\n",
      "Social NON_SUPPRESS 0.96 24\n",
      "Theoretical NON_SUPPRESS 0.88 22\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.68 17\n",
      "Understanding NON_SUPPRESS 0.68 17\n",
      "Aesthetic NON_STIMULATE 0.52 13\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Economic NON_STIMULATE 0.84 21\n",
      "Organization NON_STIMULATE 0.96 24\n",
      "Political NON_STIMULATE 1.0 25\n",
      "Resilience NON_STIMULATE 0.92 23\n",
      "Social Complexity NON_STIMULATE 1.0 25\n",
      "Social Cynicism NON_STIMULATE 1.0 25\n",
      "7502.0\n",
      "Economic NON_SUPPRESS 0.96 24\n",
      "Organization NON_SUPPRESS 0.92 23\n",
      "Positive coping NON_SUPPRESS 0.96 24\n",
      "Religious NON_SUPPRESS 1.0 25\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.88 22\n",
      "Achievement NON_STIMULATE 0.8 20\n",
      "Aesthetic NON_STIMULATE 0.92 23\n",
      "Breadth of Interest NON_STIMULATE 1.0 25\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Resilience NON_STIMULATE 0.92 23\n",
      "Social Complexity NON_STIMULATE 1.0 25\n",
      "Social MAINTAIN 0.88 22\n",
      "Social Cynicism MAINTAIN 0.24 6\n",
      "Theoretical MAINTAIN 0.96 24\n",
      "Understanding MAINTAIN 0.72 18\n",
      "8387.0\n",
      "Economic NON_SUPPRESS 1.0 25\n",
      "Empathy NON_SUPPRESS 0.88 22\n",
      "Organization NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 0.8 20\n",
      "Social NON_SUPPRESS 0.32 8\n",
      "Theoretical NON_SUPPRESS 0.36 9\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.96 24\n",
      "Understanding NON_SUPPRESS 0.76 19\n",
      "Anxiety Disorder NON_STIMULATE 0.4 10\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Religious NON_STIMULATE 1.0 25\n",
      "Social Complexity NON_STIMULATE 0.44 11\n",
      "Social Cynicism NON_STIMULATE 0.76 19\n",
      "10096.0\n",
      "Breadth of Interest NON_SUPPRESS 1.0 25\n",
      "Economic NON_SUPPRESS 0.96 24\n",
      "Empathy NON_SUPPRESS 0.88 22\n",
      "Organization NON_SUPPRESS 0.64 16\n",
      "Theoretical NON_SUPPRESS 0.84 21\n",
      "Understanding NON_SUPPRESS 0.84 21\n",
      "Positive coping NON_STIMULATE 0.92 23\n",
      "Social Complexity NON_STIMULATE 0.76 19\n",
      "Social Cynicism MAINTAIN 0.48 12\n",
      "10454.0\n",
      "Achievement NON_SUPPRESS 0.84 21\n",
      "Economic NON_SUPPRESS 0.88 22\n",
      "Organization NON_SUPPRESS 0.88 22\n",
      "Positive coping NON_SUPPRESS 0.8 20\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.96 24\n",
      "Understanding NON_SUPPRESS 0.72 18\n",
      "Aesthetic NON_STIMULATE 0.64 16\n",
      "Breadth of Interest NON_STIMULATE 1.0 25\n",
      "Empathy NON_STIMULATE 0.92 23\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Religious NON_STIMULATE 0.96 24\n",
      "Resilience NON_STIMULATE 0.96 24\n",
      "Social Complexity NON_STIMULATE 1.0 25\n",
      "Social MAINTAIN 0.88 22\n",
      "Social Cynicism MAINTAIN 0.28 7\n",
      "Theoretical MAINTAIN 0.96 24\n",
      "10605.0\n",
      "Empathy NON_SUPPRESS 0.36 9\n",
      "Positive coping NON_SUPPRESS 0.72 18\n",
      "Social NON_SUPPRESS 1.0 25\n",
      "Social Cynicism NON_SUPPRESS 0.96 24\n",
      "Theoretical NON_SUPPRESS 0.68 17\n",
      "Uncertainty Avoidance NON_SUPPRESS 1.0 25\n",
      "Understanding NON_SUPPRESS 0.84 21\n",
      "Achievement NON_STIMULATE 0.8 20\n",
      "Aesthetic NON_STIMULATE 0.84 21\n",
      "Breadth of Interest NON_STIMULATE 0.68 17\n",
      "Economic NON_STIMULATE 0.76 19\n",
      "Organization NON_STIMULATE 0.96 24\n",
      "Political NON_STIMULATE 1.0 25\n",
      "Religious NON_STIMULATE 0.96 24\n",
      "Resilience NON_STIMULATE 0.92 23\n",
      "Social Complexity NON_STIMULATE 0.96 24\n",
      "11712.0\n",
      "Achievement NON_SUPPRESS 0.76 19\n",
      "Aesthetic NON_SUPPRESS 0.96 24\n",
      "Organization NON_SUPPRESS 0.92 23\n",
      "Positive coping NON_SUPPRESS 0.68 17\n",
      "Religious NON_SUPPRESS 0.6 15\n",
      "Theoretical NON_SUPPRESS 0.52 13\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.84 21\n",
      "Understanding NON_SUPPRESS 0.64 16\n",
      "Economic NON_STIMULATE 0.56 14\n",
      "Empathy NON_STIMULATE 0.68 17\n",
      "Political NON_STIMULATE 1.0 25\n",
      "Resilience NON_STIMULATE 0.96 24\n",
      "Social Complexity NON_STIMULATE 1.0 25\n",
      "Breadth of Interest MAINTAIN 0.72 18\n",
      "Social MAINTAIN 0.96 24\n",
      "Social Cynicism MAINTAIN 0.4 10\n",
      "12703.0\n",
      "Achievement NON_SUPPRESS 0.64 16\n",
      "Aesthetic NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 1.0 25\n",
      "Religious NON_SUPPRESS 0.88 22\n",
      "Resilience NON_SUPPRESS 1.0 25\n",
      "Social Cynicism NON_SUPPRESS 0.36 9\n",
      "Uncertainty Avoidance NON_SUPPRESS 1.0 25\n",
      "Understanding NON_SUPPRESS 0.76 19\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Economic NON_STIMULATE 0.84 21\n",
      "Empathy NON_STIMULATE 0.96 24\n",
      "Organization NON_STIMULATE 0.96 24\n",
      "Political NON_STIMULATE 0.96 24\n",
      "Social Complexity NON_STIMULATE 0.72 18\n",
      "Social MAINTAIN 0.76 19\n",
      "Theoretical MAINTAIN 0.96 24\n",
      "14049.0\n",
      "Organization SUPPRESS 0.6 15\n",
      "Political NON_SUPPRESS 0.8 20\n",
      "Positive coping NON_SUPPRESS 0.92 23\n",
      "Social NON_SUPPRESS 1.0 25\n",
      "Social Cynicism NON_SUPPRESS 0.96 24\n",
      "Theoretical NON_SUPPRESS 0.52 13\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.96 24\n",
      "Aesthetic NON_STIMULATE 0.52 13\n",
      "Breadth of Interest NON_STIMULATE 1.0 25\n",
      "Economic NON_STIMULATE 0.68 17\n",
      "Resilience NON_STIMULATE 0.84 21\n",
      "Understanding NON_STIMULATE 0.84 21\n",
      "14185.0\n",
      "Aesthetic NON_SUPPRESS 0.64 16\n",
      "Breadth of Interest NON_SUPPRESS 0.76 19\n",
      "Economic NON_SUPPRESS 1.0 25\n",
      "Political NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 0.6 15\n",
      "Social NON_SUPPRESS 0.88 22\n",
      "Social Cynicism NON_SUPPRESS 0.92 23\n",
      "Theoretical NON_SUPPRESS 0.84 21\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.96 24\n",
      "Empathy NON_STIMULATE 0.48 12\n",
      "Religious NON_STIMULATE 1.0 25\n",
      "Resilience NON_STIMULATE 0.88 22\n",
      "Social Complexity NON_STIMULATE 0.96 24\n",
      "Understanding NON_STIMULATE 0.44 11\n",
      "14351.0\n",
      "Achievement NON_SUPPRESS 0.96 24\n",
      "Organization NON_SUPPRESS 0.96 24\n",
      "Political NON_SUPPRESS 1.0 25\n",
      "Positive coping NON_SUPPRESS 1.0 25\n",
      "Religious NON_SUPPRESS 0.96 24\n",
      "Uncertainty Avoidance NON_SUPPRESS 0.88 22\n",
      "Aesthetic NON_STIMULATE 1.0 25\n",
      "Breadth of Interest NON_STIMULATE 0.96 24\n",
      "Economic NON_STIMULATE 0.76 19\n",
      "Empathy NON_STIMULATE 1.0 25\n",
      "Resilience NON_STIMULATE 0.96 24\n",
      "Social Complexity NON_STIMULATE 0.88 22\n",
      "Social MAINTAIN 1.0 25\n",
      "Social Cynicism MAINTAIN 0.32 8\n",
      "Theoretical MAINTAIN 0.96 24\n",
      "Understanding MAINTAIN 0.8 20\n"
     ]
    }
   ],
   "source": [
    "threshold_ss = 0.65\n",
    "threshold_maintain = 0.85\n",
    "threshold_non = 0.2\n",
    "threshold_judge = 0\n",
    "\n",
    "\n",
    "def get_table1(data_csv_train, data_csv_test, stat_csv_23):\n",
    "    data_new_diff_count_total = pd.read_csv(stat_csv_23)\n",
    "\n",
    "    table1_columns = data_new_diff_count_total['steer_dim'].unique()\n",
    "    table1_columns = table1_columns[~np.isnan(table1_columns)]\n",
    "    value_dims = data_new_diff_count_total.columns[1:]\n",
    "    table1 = pd.DataFrame(columns=table1_columns, index=value_dims)\n",
    "\n",
    "\n",
    "    players_list_train = data_csv_train['player_name'].unique()\n",
    "    #players_list_train = players_list_local[~pd.isnull(players_list_local)]\n",
    "\n",
    "    players_list_test = data_csv_test['player_name'].unique()\n",
    "    players_list_test = players_list_test[~pd.isnull(players_list_test)]\n",
    "\n",
    "    standard_data = data_csv_test[data_csv_test['steer_dim'].isnull()]\n",
    "\n",
    "    for steer_dim in table1_columns:\n",
    "        assert not np.isnan(steer_dim)\n",
    "        print(steer_dim)\n",
    "\n",
    "        steer_dim_row = data_new_diff_count_total[data_new_diff_count_total['steer_dim'] == steer_dim]\n",
    "        stimulated_dims = []\n",
    "        suppressed_dims = []\n",
    "        maintained_dims = []\n",
    "        non_suppressed_dims = []\n",
    "        non_stimulated_dims = []\n",
    "        uncontrolled_dims = []\n",
    "\n",
    "        for column in value_dims:\n",
    "            assert column != 'steer_dim'\n",
    "            #split cell by /\n",
    "            counts = steer_dim_row[column].values[0].split('/')   \n",
    "            if int(counts[0]) / len(players_list_train) > threshold_ss:\n",
    "                stimulated_dims.append(column)\n",
    "            elif int(counts[1]) / len(players_list_train) > threshold_ss:\n",
    "                suppressed_dims.append(column)\n",
    "            elif int(counts[2]) / len(players_list_train) > threshold_maintain:\n",
    "                maintained_dims.append(column)\n",
    "            elif int(counts[1]) / len(players_list_train) < threshold_non:\n",
    "                non_suppressed_dims.append(column)\n",
    "            elif int(counts[0]) / len(players_list_train) < threshold_non:\n",
    "                non_stimulated_dims.append(column)\n",
    "            else:\n",
    "                uncontrolled_dims.append(column)\n",
    "\n",
    "        steer_dim_data = data_csv_test[data_csv_test['steer_dim'] == steer_dim]\n",
    "        for value_dim in stimulated_dims:\n",
    "            count_correct_steer = 0\n",
    "            for player_name in players_list_test:\n",
    "                steered_player_data = steer_dim_data[steer_dim_data['player_name'] == player_name][value_dim].values[0]\n",
    "                standard_player_data = standard_data[standard_data['player_name'] == player_name][value_dim].values[0]\n",
    "                if steered_player_data - standard_player_data > threshold_judge:\n",
    "                    count_correct_steer += 1\n",
    "            print(value_dim, 'SITMULATE', count_correct_steer / len(players_list_test), count_correct_steer)\n",
    "            #edit the table\n",
    "            table1.loc[value_dim, steer_dim] = 'STIMULATE,' + str(count_correct_steer / len(players_list_test))\n",
    "\n",
    "        for value_dim in suppressed_dims:\n",
    "            count_correct_steer = 0\n",
    "            for player_name in players_list_test:\n",
    "                steered_player_data = steer_dim_data[steer_dim_data['player_name'] == player_name][value_dim].values[0]\n",
    "                standard_player_data = standard_data[standard_data['player_name'] == player_name][value_dim].values[0]\n",
    "                if -(steered_player_data - standard_player_data) > threshold_judge:\n",
    "                    count_correct_steer += 1\n",
    "            print(value_dim, 'SUPPRESS', count_correct_steer / len(players_list_test), count_correct_steer)\n",
    "            table1.loc[value_dim, steer_dim] = 'SUPPRESS,' + str(count_correct_steer / len(players_list_test))\n",
    "            \n",
    "        for value_dim in non_suppressed_dims:\n",
    "            count_correct_steer = 0\n",
    "            for player_name in players_list_test:\n",
    "                steered_player_data = steer_dim_data[steer_dim_data['player_name'] == player_name][value_dim].values[0]\n",
    "                standard_player_data = standard_data[standard_data['player_name'] == player_name][value_dim].values[0]\n",
    "                if steered_player_data - standard_player_data >= -threshold_judge:\n",
    "                    count_correct_steer += 1\n",
    "            print(value_dim, 'NON_SUPPRESS', count_correct_steer / len(players_list_test), count_correct_steer)\n",
    "            table1.loc[value_dim, steer_dim] = 'NON_SUPPRESS,' + str(count_correct_steer / len(players_list_test))\n",
    "\n",
    "        for value_dim in non_stimulated_dims:\n",
    "            count_correct_steer = 0\n",
    "            for player_name in players_list_test:\n",
    "                steered_player_data = steer_dim_data[steer_dim_data['player_name'] == player_name][value_dim].values[0]\n",
    "                standard_player_data = standard_data[standard_data['player_name'] == player_name][value_dim].values[0]\n",
    "                if steered_player_data - standard_player_data <= threshold_judge:\n",
    "                    count_correct_steer += 1\n",
    "            print(value_dim, 'NON_STIMULATE', count_correct_steer / len(players_list_test), count_correct_steer)   \n",
    "            table1.loc[value_dim, steer_dim] = 'NON_STIMULATE,' + str(count_correct_steer / len(players_list_test))\n",
    "        \n",
    "        for value_dim in maintained_dims:\n",
    "            count_correct_steer = 0\n",
    "            for player_name in players_list_test:\n",
    "                steered_player_data = steer_dim_data[steer_dim_data['player_name'] == player_name][value_dim].values[0]\n",
    "                standard_player_data = standard_data[standard_data['player_name'] == player_name][value_dim].values[0]\n",
    "                if abs(steered_player_data - standard_player_data) <= threshold_judge:\n",
    "                    count_correct_steer += 1\n",
    "            print(value_dim, 'MAINTAIN', count_correct_steer / len(players_list_test), count_correct_steer)\n",
    "            table1.loc[value_dim, steer_dim] = 'MAINTAIN,' + str(count_correct_steer / len(players_list_test))\n",
    "    return table1\n",
    "\n",
    "\n",
    "table1_gemma = get_table1(data_csv_gemma_train, data_csv_gemma_test, 'value_dims_rsd_gemma/23_stat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NON_STIMULATE,0.6\n",
      "NON_STIMULATE,0.8\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.84\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.84\n",
      "NON_SUPPRESS,0.92\n",
      "NON_STIMULATE,0.8\n",
      "NON_SUPPRESS,0.84\n",
      "NON_STIMULATE,0.8\n",
      "NON_SUPPRESS,0.76\n",
      "NON_SUPPRESS,0.64\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,0.8\n",
      "NON_STIMULATE,0.88\n",
      "NON_SUPPRESS,0.76\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,0.64\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.52\n",
      "NON_STIMULATE,0.84\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.48\n",
      "NON_STIMULATE,0.52\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.64\n",
      "NON_STIMULATE,0.84\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.52\n",
      "NON_SUPPRESS,0.64\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.68\n",
      "STIMULATE,0.8\n",
      "STIMULATE,0.88\n",
      "NON_SUPPRESS,0.4\n",
      "NON_STIMULATE,0.4\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.96\n",
      "SUPPRESS,0.04\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.52\n",
      "NON_STIMULATE,0.6\n",
      "NON_STIMULATE,0.76\n",
      "NON_STIMULATE,0.96\n",
      "SUPPRESS,0.08\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.68\n",
      "MAINTAIN,0.72\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.76\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.92\n",
      "NON_STIMULATE,0.84\n",
      "NON_STIMULATE,0.8\n",
      "NON_SUPPRESS,0.84\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,0.68\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.84\n",
      "NON_STIMULATE,0.84\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.88\n",
      "NON_STIMULATE,0.76\n",
      "NON_STIMULATE,0.56\n",
      "NON_STIMULATE,0.84\n",
      "NON_STIMULATE,0.68\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.76\n",
      "NON_STIMULATE,0.88\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.76\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.8\n",
      "NON_STIMULATE,0.88\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.88\n",
      "NON_STIMULATE,0.88\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,0.88\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.36\n",
      "NON_STIMULATE,0.68\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.48\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.88\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.84\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.64\n",
      "NON_SUPPRESS,0.88\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.92\n",
      "NON_STIMULATE,0.96\n",
      "SUPPRESS,0.6\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.8\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.8\n",
      "NON_SUPPRESS,0.8\n",
      "NON_SUPPRESS,0.48\n",
      "NON_SUPPRESS,0.64\n",
      "STIMULATE,0.44\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.72\n",
      "NON_SUPPRESS,0.76\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,0.72\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.8\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.8\n",
      "NON_SUPPRESS,0.72\n",
      "NON_SUPPRESS,0.68\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.6\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,1.0\n",
      "STIMULATE,0.0\n",
      "NON_SUPPRESS,0.72\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.6\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.6\n",
      "NON_SUPPRESS,0.88\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,0.72\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.36\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.44\n",
      "NON_STIMULATE,0.92\n",
      "SUPPRESS,0.68\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.4\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.92\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_STIMULATE,0.84\n",
      "NON_STIMULATE,0.88\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.8\n",
      "MAINTAIN,0.88\n",
      "MAINTAIN,0.08\n",
      "NON_STIMULATE,0.96\n",
      "NON_SUPPRESS,0.92\n",
      "MAINTAIN,0.84\n",
      "MAINTAIN,1.0\n",
      "MAINTAIN,0.8\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.96\n",
      "MAINTAIN,0.76\n",
      "MAINTAIN,0.88\n",
      "NON_SUPPRESS,0.96\n",
      "MAINTAIN,0.88\n",
      "NON_SUPPRESS,0.32\n",
      "MAINTAIN,0.88\n",
      "NON_SUPPRESS,1.0\n",
      "MAINTAIN,0.96\n",
      "MAINTAIN,0.76\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.88\n",
      "MAINTAIN,1.0\n",
      "NON_STIMULATE,0.6\n",
      "NON_STIMULATE,0.84\n",
      "SUPPRESS,0.2\n",
      "NON_STIMULATE,0.92\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_SUPPRESS,0.28\n",
      "NON_STIMULATE,0.48\n",
      "NON_STIMULATE,0.96\n",
      "SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.72\n",
      "NON_STIMULATE,0.64\n",
      "NON_SUPPRESS,0.6\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.44\n",
      "NON_STIMULATE,0.76\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,1.0\n",
      "NON_STIMULATE,0.72\n",
      "NON_STIMULATE,0.96\n",
      "NON_STIMULATE,0.88\n",
      "MAINTAIN,0.4\n",
      "MAINTAIN,0.8\n",
      "NON_SUPPRESS,0.08\n",
      "MAINTAIN,0.88\n",
      "MAINTAIN,0.48\n",
      "NON_SUPPRESS,0.28\n",
      "MAINTAIN,0.76\n",
      "NON_SUPPRESS,0.96\n",
      "MAINTAIN,0.32\n",
      "SUPPRESS,0.96\n",
      "MAINTAIN,0.36\n",
      "NON_SUPPRESS,0.28\n",
      "NON_SUPPRESS,0.96\n",
      "NON_STIMULATE,1.0\n",
      "MAINTAIN,0.24\n",
      "NON_STIMULATE,0.76\n",
      "MAINTAIN,0.48\n",
      "MAINTAIN,0.28\n",
      "NON_SUPPRESS,0.96\n",
      "MAINTAIN,0.4\n",
      "NON_SUPPRESS,0.36\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.92\n",
      "MAINTAIN,0.32\n",
      "NON_SUPPRESS,1.0\n",
      "MAINTAIN,0.92\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,0.76\n",
      "MAINTAIN,0.8\n",
      "MAINTAIN,0.92\n",
      "STIMULATE,0.8\n",
      "MAINTAIN,1.0\n",
      "NON_SUPPRESS,0.96\n",
      "MAINTAIN,0.84\n",
      "MAINTAIN,0.92\n",
      "NON_STIMULATE,0.12\n",
      "NON_SUPPRESS,0.88\n",
      "MAINTAIN,0.96\n",
      "NON_SUPPRESS,0.36\n",
      "NON_SUPPRESS,0.84\n",
      "MAINTAIN,0.96\n",
      "NON_SUPPRESS,0.68\n",
      "NON_SUPPRESS,0.52\n",
      "MAINTAIN,0.96\n",
      "NON_SUPPRESS,0.52\n",
      "NON_SUPPRESS,0.84\n",
      "MAINTAIN,0.96\n",
      "NON_SUPPRESS,0.76\n",
      "NON_SUPPRESS,0.6\n",
      "STIMULATE,0.48\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.88\n",
      "STIMULATE,1.0\n",
      "NON_SUPPRESS,0.64\n",
      "NON_SUPPRESS,0.64\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,0.68\n",
      "NON_SUPPRESS,0.88\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.84\n",
      "NON_SUPPRESS,1.0\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.96\n",
      "NON_SUPPRESS,0.88\n",
      "NON_STIMULATE,0.88\n",
      "NON_SUPPRESS,0.84\n",
      "NON_STIMULATE,0.68\n",
      "NON_SUPPRESS,0.92\n",
      "NON_STIMULATE,0.88\n",
      "NON_SUPPRESS,0.48\n",
      "MAINTAIN,0.96\n",
      "NON_STIMULATE,0.52\n",
      "NON_SUPPRESS,0.92\n",
      "NON_SUPPRESS,0.76\n",
      "NON_SUPPRESS,0.84\n",
      "MAINTAIN,0.76\n",
      "NON_SUPPRESS,0.6\n",
      "NON_SUPPRESS,0.68\n",
      "MAINTAIN,0.72\n",
      "NON_SUPPRESS,0.76\n",
      "NON_SUPPRESS,0.84\n",
      "NON_SUPPRESS,0.72\n",
      "NON_SUPPRESS,0.84\n",
      "NON_SUPPRESS,0.64\n",
      "NON_SUPPRESS,0.76\n",
      "NON_STIMULATE,0.84\n",
      "NON_STIMULATE,0.44\n",
      "MAINTAIN,0.8\n",
      "\\begin{table*}[ht]\n",
      "\\caption{Value steering using SAE features for the Gemma-2B-IT model. Expected stimulated values are highlighted in red, along with their actual success rate during testing. Expected suppressed values are marked in Purple. Maintained values are shown in gray. Light red indicates values that are expected to be at least not suppressed, while light purple represents values that are expected to be at least not stimulated. Blank cells correspond to uncontrollable values. The bottom of the table indicates the count of each of the six expected categories and their average success rates.}\n",
      "\\label{table: sae-steering-gemma}\n",
      "\\begin{center}\n",
      "\\scalebox{0.5}{\\begin{tabular}{c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c}\n",
      "\\toprule\n",
      "Value & \\bf 428 & \\bf 1025 & \\bf 1312 & \\bf 1341 & \\bf 1975 & \\bf 2221 & \\bf 2965 & \\bf 3183 & \\bf 3402 & \\bf 4752 & \\bf 6188 & \\bf 6216 & \\bf 6619 & \\bf 6884 & \\bf 7502 & \\bf 8387 & \\bf 10096 & \\bf 10454 & \\bf 10605 & \\bf 11712 & \\bf 12703 & \\bf 14049 & \\bf 14185 & \\bf 14351 \\\\\n",
      "\\hline\n",
      "\\small Achievement & \\colorbox{blue!20} 0.60 & \\colorbox{blue!20} 0.80 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 0.96 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.84 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.84 & \\colorbox{red!20} 0.92 & - & - & \\colorbox{blue!20} 0.80 & - & - & \\colorbox{red!20} 0.84 & \\colorbox{blue!20} 0.80 & \\colorbox{red!20} 0.76 & \\colorbox{red!20} 0.64 & - & - & \\colorbox{red!20} 0.96  \\\\\n",
      "\\small Aesthetic & \\colorbox{blue!20} 0.80 & \\colorbox{blue!20} 0.88 & \\colorbox{red!20} 0.76 & \\colorbox{red!20} 0.96 & \\colorbox{blue!20} 0.64 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.96 & - & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.52 & \\colorbox{blue!20} 0.84 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.48 & \\colorbox{blue!20} 0.52 & \\colorbox{blue!20} 0.92 & - & - & \\colorbox{blue!20} 0.64 & \\colorbox{blue!20} 0.84 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 0.52 & \\colorbox{red!20} 0.64 & \\colorbox{blue!20} 1.00  \\\\\n",
      "\\small Anxiety Disorder & \\colorbox{red!20} 0.68 & - & \\colorbox{red!50} 0.80 & - & - & - & - & \\colorbox{red!50} 0.88 & - & \\colorbox{red!20} 0.40 & - & - & - & - & - & \\colorbox{blue!20} 0.40 & - & - & - & - & - & - & - & -  \\\\\n",
      "\\small Breadth of Interest & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!50} 0.04 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.52 & \\colorbox{blue!20} 0.60 & \\colorbox{blue!20} 0.76 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!50} 0.08 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.68 & \\colorbox{gray!20} 0.72 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.76 & \\colorbox{blue!20} 0.96  \\\\\n",
      "\\small Economic & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.92 & \\colorbox{blue!20} 0.84 & \\colorbox{blue!20} 0.80 & \\colorbox{red!20} 0.84 & - & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.96 & \\colorbox{blue!20} 0.68 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.84 & \\colorbox{blue!20} 0.84 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.88 & \\colorbox{blue!20} 0.76 & \\colorbox{blue!20} 0.56 & \\colorbox{blue!20} 0.84 & \\colorbox{blue!20} 0.68 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 0.76  \\\\\n",
      "\\small Empathy & - & \\colorbox{blue!20} 0.88 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.76 & \\colorbox{blue!20} 1.00 & - & \\colorbox{blue!20} 0.80 & \\colorbox{blue!20} 0.88 & - & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.88 & \\colorbox{blue!20} 0.88 & - & - & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 0.88 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.36 & \\colorbox{blue!20} 0.68 & \\colorbox{blue!20} 0.96 & - & \\colorbox{blue!20} 0.48 & \\colorbox{blue!20} 1.00  \\\\\n",
      "\\small Organization & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.88 & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.96 & - & \\colorbox{blue!20} 1.00 & - & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.84 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.64 & \\colorbox{red!20} 0.88 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.92 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!50} 0.60 & - & \\colorbox{red!20} 0.96  \\\\\n",
      "\\small Political & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 1.00 & - & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.92 & - & \\colorbox{red!20} 1.00 & - & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.96 & - & - & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.80 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 1.00  \\\\\n",
      "\\small Positive coping & \\colorbox{red!20} 0.80 & \\colorbox{red!20} 0.80 & \\colorbox{red!20} 0.48 & \\colorbox{red!20} 0.64 & \\colorbox{red!50} 0.44 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.96 & - & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.72 & \\colorbox{red!20} 0.76 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 0.72 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.80 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.80 & \\colorbox{red!20} 0.72 & \\colorbox{red!20} 0.68 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.60 & \\colorbox{red!20} 1.00  \\\\\n",
      "\\small Religious & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 1.00 & \\colorbox{red!50} 0.00 & \\colorbox{red!20} 0.72 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.60 & \\colorbox{red!20} 0.96 & - & - & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 1.00 & - & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.60 & \\colorbox{red!20} 0.88 & - & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.96  \\\\\n",
      "\\small Resilience & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.96 & \\colorbox{blue!20} 0.72 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.36 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.44 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!50} 0.68 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.40 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.92 & - & - & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.92 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 1.00 & \\colorbox{blue!20} 0.84 & \\colorbox{blue!20} 0.88 & \\colorbox{blue!20} 0.96  \\\\\n",
      "\\small Social & \\colorbox{blue!20} 0.80 & \\colorbox{gray!20} 0.88 & \\colorbox{gray!20} 0.08 & \\colorbox{blue!20} 0.96 & \\colorbox{red!20} 0.92 & \\colorbox{gray!20} 0.84 & \\colorbox{gray!20} 1.00 & - & \\colorbox{gray!20} 0.80 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.96 & \\colorbox{gray!20} 0.76 & \\colorbox{gray!20} 0.88 & \\colorbox{red!20} 0.96 & \\colorbox{gray!20} 0.88 & \\colorbox{red!20} 0.32 & - & \\colorbox{gray!20} 0.88 & \\colorbox{red!20} 1.00 & \\colorbox{gray!20} 0.96 & \\colorbox{gray!20} 0.76 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.88 & \\colorbox{gray!20} 1.00  \\\\\n",
      "\\small Social Complexity & \\colorbox{blue!20} 0.60 & \\colorbox{blue!20} 0.84 & \\colorbox{blue!50} 0.20 & \\colorbox{blue!20} 0.92 & \\colorbox{red!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{red!20} 0.28 & \\colorbox{blue!20} 0.48 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!50} 0.96 & \\colorbox{red!20} 0.72 & \\colorbox{blue!20} 0.64 & \\colorbox{red!20} 0.60 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.44 & \\colorbox{blue!20} 0.76 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{blue!20} 0.72 & - & \\colorbox{blue!20} 0.96 & \\colorbox{blue!20} 0.88  \\\\\n",
      "\\small Social Cynicism & \\colorbox{gray!20} 0.40 & \\colorbox{gray!20} 0.80 & \\colorbox{red!20} 0.08 & \\colorbox{gray!20} 0.88 & \\colorbox{gray!20} 0.48 & \\colorbox{red!20} 0.28 & \\colorbox{gray!20} 0.76 & \\colorbox{red!20} 0.96 & \\colorbox{gray!20} 0.32 & \\colorbox{blue!50} 0.96 & \\colorbox{gray!20} 0.36 & \\colorbox{red!20} 0.28 & \\colorbox{red!20} 0.96 & \\colorbox{blue!20} 1.00 & \\colorbox{gray!20} 0.24 & \\colorbox{blue!20} 0.76 & \\colorbox{gray!20} 0.48 & \\colorbox{gray!20} 0.28 & \\colorbox{red!20} 0.96 & \\colorbox{gray!20} 0.40 & \\colorbox{red!20} 0.36 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.92 & \\colorbox{gray!20} 0.32  \\\\\n",
      "\\small Theoretical & \\colorbox{red!20} 1.00 & \\colorbox{gray!20} 0.92 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 0.76 & \\colorbox{gray!20} 0.80 & \\colorbox{gray!20} 0.92 & \\colorbox{red!50} 0.80 & \\colorbox{gray!20} 1.00 & \\colorbox{red!20} 0.96 & \\colorbox{gray!20} 0.84 & \\colorbox{gray!20} 0.92 & \\colorbox{blue!20} 0.12 & \\colorbox{red!20} 0.88 & \\colorbox{gray!20} 0.96 & \\colorbox{red!20} 0.36 & \\colorbox{red!20} 0.84 & \\colorbox{gray!20} 0.96 & \\colorbox{red!20} 0.68 & \\colorbox{red!20} 0.52 & \\colorbox{gray!20} 0.96 & \\colorbox{red!20} 0.52 & \\colorbox{red!20} 0.84 & \\colorbox{gray!20} 0.96  \\\\\n",
      "\\tiny Uncertainty Avoidance & \\colorbox{red!20} 0.76 & \\colorbox{red!20} 0.60 & \\colorbox{red!50} 0.48 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.96 & - & \\colorbox{red!20} 0.88 & \\colorbox{red!50} 1.00 & \\colorbox{red!20} 0.64 & - & \\colorbox{red!20} 0.64 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 0.68 & \\colorbox{red!20} 0.88 & \\colorbox{red!20} 0.96 & - & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.84 & \\colorbox{red!20} 1.00 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.96 & \\colorbox{red!20} 0.88  \\\\\n",
      "\\small Understanding & \\colorbox{blue!20} 0.88 & \\colorbox{red!20} 0.84 & \\colorbox{blue!20} 0.68 & \\colorbox{red!20} 0.92 & \\colorbox{blue!20} 0.88 & \\colorbox{red!20} 0.48 & \\colorbox{gray!20} 0.96 & \\colorbox{blue!20} 0.52 & \\colorbox{red!20} 0.92 & \\colorbox{red!20} 0.76 & \\colorbox{red!20} 0.84 & \\colorbox{gray!20} 0.76 & \\colorbox{red!20} 0.60 & \\colorbox{red!20} 0.68 & \\colorbox{gray!20} 0.72 & \\colorbox{red!20} 0.76 & \\colorbox{red!20} 0.84 & \\colorbox{red!20} 0.72 & \\colorbox{red!20} 0.84 & \\colorbox{red!20} 0.64 & \\colorbox{red!20} 0.76 & \\colorbox{blue!20} 0.84 & \\colorbox{blue!20} 0.44 & \\colorbox{gray!20} 0.80  \\\\\n",
      " \\midrule\n",
      "\\colorbox{red!50} STIMULATE & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{2(0.64)} & \\textbf{0(nan)} & \\textbf{1(0.44)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{4(0.67)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)}  \\\\\n",
      "\\colorbox{blue!50} SUPPRESSED & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{2(0.12)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{3(0.867)} & \\textbf{0(nan)} & \\textbf{1(0.08)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{1(0.6)} & \\textbf{0(nan)} & \\textbf{0(nan)}  \\\\\n",
      "\\colorbox{red!20} NON-SUPPRESSED & \\textbf{8(0.88)} & \\textbf{7(0.874)} & \\textbf{7(0.743)} & \\textbf{7(0.886)} & \\textbf{6(0.807)} & \\textbf{4(0.66)} & \\textbf{8(0.85)} & \\textbf{2(0.7)} & \\textbf{6(0.853)} & \\textbf{6(0.787)} & \\textbf{8(0.795)} & \\textbf{7(0.863)} & \\textbf{8(0.75)} & \\textbf{5(0.784)} & \\textbf{5(0.944)} & \\textbf{8(0.76)} & \\textbf{6(0.86)} & \\textbf{6(0.847)} & \\textbf{7(0.794)} & \\textbf{8(0.74)} & \\textbf{8(0.83)} & \\textbf{6(0.86)} & \\textbf{9(0.844)} & \\textbf{6(0.96)}  \\\\\n",
      "\\colorbox{blue!20} NON-STIMULATED & \\textbf{7(0.794)} & \\textbf{6(0.887)} & \\textbf{5(0.856)} & \\textbf{7(0.949)} & \\textbf{8(0.865)} & \\textbf{9(0.956)} & \\textbf{3(0.987)} & \\textbf{5(0.656)} & \\textbf{7(0.886)} & \\textbf{4(0.78)} & \\textbf{6(0.907)} & \\textbf{5(0.88)} & \\textbf{5(0.672)} & \\textbf{8(0.9)} & \\textbf{6(0.933)} & \\textbf{5(0.712)} & \\textbf{2(0.84)} & \\textbf{7(0.92)} & \\textbf{9(0.876)} & \\textbf{5(0.84)} & \\textbf{6(0.9)} & \\textbf{5(0.776)} & \\textbf{5(0.752)} & \\textbf{6(0.927)}  \\\\\n",
      "\\colorbox{gray!20} MAINTAINED & \\textbf{1(0.4)} & \\textbf{3(0.867)} & \\textbf{1(0.08)} & \\textbf{1(0.88)} & \\textbf{1(0.48)} & \\textbf{2(0.82)} & \\textbf{4(0.91)} & \\textbf{0(nan)} & \\textbf{3(0.707)} & \\textbf{0(nan)} & \\textbf{2(0.6)} & \\textbf{3(0.813)} & \\textbf{1(0.88)} & \\textbf{0(nan)} & \\textbf{4(0.7)} & \\textbf{0(nan)} & \\textbf{1(0.48)} & \\textbf{3(0.707)} & \\textbf{0(nan)} & \\textbf{3(0.693)} & \\textbf{2(0.86)} & \\textbf{0(nan)} & \\textbf{0(nan)} & \\textbf{4(0.77)}  \\\\\n",
      "UNCONTROLLED & \\textbf{1} & \\textbf{1} & \\textbf{0} & \\textbf{2} & \\textbf{1} & \\textbf{2} & \\textbf{2} & \\textbf{6} & \\textbf{1} & \\textbf{4} & \\textbf{1} & \\textbf{1} & \\textbf{3} & \\textbf{4} & \\textbf{2} & \\textbf{4} & \\textbf{8} & \\textbf{1} & \\textbf{1} & \\textbf{1} & \\textbf{1} & \\textbf{5} & \\textbf{3} & \\textbf{1}  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{center}\n",
      "\\end{table*}\n",
      "\\begin{table*}[ht]\n",
      "\\caption{Value steering using SAE features for the Gemma-2B-IT model. Expected stimulated values are highlighted in red, along with their actual success rate during testing. Expected suppressed values are marked in Purple. Maintained values are shown in gray. Light red indicates values that are expected to be at least not suppressed, while light purple represents values that are expected to be at least not stimulated. Blank cells correspond to uncontrollable values. The bottom of the table indicates the count of each of the six expected categories and their average success rates.}\n",
      "\\label{table: sae-steering-gemma}\n",
      "\\begin{center}\n",
      "\\scalebox{0.5}{\\begin{tabular}{c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c@{\\hspace{1.5pt}}|c}\n",
      "\\toprule\n",
      "Value & \\rotatebox{90}{\\bf Achievement} & \\rotatebox{90}{\\bf Aesthetic} & \\rotatebox{90}{\\bf Anxiety Disorder} & \\rotatebox{90}{\\bf Breadth of Interest} & \\rotatebox{90}{\\bf Economic} & \\rotatebox{90}{\\bf Empathy} & \\rotatebox{90}{\\bf Organization} & \\rotatebox{90}{\\bf Political} & \\rotatebox{90}{\\bf Positive coping} & \\rotatebox{90}{\\bf Religious} & \\rotatebox{90}{\\bf Resilience} & \\rotatebox{90}{\\bf Social} & \\rotatebox{90}{\\bf Social Complexity} & \\rotatebox{90}{\\bf Social Cynicism} & \\rotatebox{90}{\\bf Theoretical} & \\rotatebox{90}{\\bf Uncertainty Avoidance} & \\rotatebox{90}{\\bf Understanding} &\\rotatebox{90} {\\bf STIMULATE} & \\rotatebox{90} {\\bf SUPPRESS} & \\rotatebox{90} {\\bf NON-SUPPRESS}& \\rotatebox{90} {\\bf NON-STIMULATE} & \\rotatebox{90} {\\bf MAINTAIN} & \\rotatebox{90} {\\bf UNCONTROLLED} \\\\\n",
      "\\hline\n",
      "\\small 428.0 & \\colorbox{blue!20}{0.60} & \\colorbox{blue!20}{0.80} & \\colorbox{red!20}{0.68} & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{0.96} & - & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.80} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.80} & \\colorbox{blue!20}{0.60} & \\colorbox{gray!20}{0.40} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.76} & \\colorbox{blue!20}{0.88}  & 0(nan) & 0(nan) & 8(0.88) & 7(0.794) & 1(0.4) & 1 \\ \\\\\n",
      "\\small 1025.0 & \\colorbox{blue!20}{0.80} & \\colorbox{blue!20}{0.88} & - & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{0.88} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.80} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.96} & \\colorbox{gray!20}{0.88} & \\colorbox{blue!20}{0.84} & \\colorbox{gray!20}{0.80} & \\colorbox{gray!20}{0.92} & \\colorbox{red!20}{0.60} & \\colorbox{red!20}{0.84}  & 0(nan) & 0(nan) & 7(0.874) & 6(0.887) & 3(0.867) & 1 \\ \\\\\n",
      "\\small 1312.0 & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{0.76} & \\colorbox{red!50}{0.80} & \\colorbox{blue!50}{0.04} & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.48} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.72} & \\colorbox{gray!20}{0.08} & \\colorbox{blue!50}{0.20} & \\colorbox{red!20}{0.08} & \\colorbox{red!20}{0.96} & \\colorbox{red!50}{0.48} & \\colorbox{blue!20}{0.68}  & 2(0.64) & 2(0.12) & 7(0.743) & 5(0.856) & 1(0.08) & 0 \\ \\\\\n",
      "\\small 1341.0 & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{0.96} & - & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{0.92} & \\colorbox{blue!20}{0.96} & - & \\colorbox{red!20}{0.64} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.92} & \\colorbox{gray!20}{0.88} & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.92}  & 0(nan) & 0(nan) & 7(0.886) & 7(0.949) & 1(0.88) & 2 \\ \\\\\n",
      "\\small 1975.0 & \\colorbox{blue!20}{0.92} & \\colorbox{blue!20}{0.64} & - & \\colorbox{blue!20}{0.92} & \\colorbox{blue!20}{0.84} & \\colorbox{blue!20}{0.76} & \\colorbox{red!20}{0.88} & \\colorbox{blue!20}{0.96} & \\colorbox{red!50}{0.44} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.36} & \\colorbox{red!20}{0.92} & \\colorbox{red!20}{0.96} & \\colorbox{gray!20}{0.48} & \\colorbox{red!20}{0.76} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.88}  & 1(0.44) & 0(nan) & 6(0.807) & 8(0.865) & 1(0.48) & 1 \\ \\\\\n",
      "\\small 2221.0 & \\colorbox{red!20}{0.88} & \\colorbox{blue!20}{0.96} & - & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{0.80} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.92} & \\colorbox{blue!20}{0.92} & \\colorbox{gray!20}{0.84} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.28} & \\colorbox{gray!20}{0.80} & - & \\colorbox{red!20}{0.48}  & 0(nan) & 0(nan) & 4(0.66) & 9(0.956) & 2(0.82) & 2 \\ \\\\\n",
      "\\small 2965.0 & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.96} & - & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.84} & - & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.92} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{1.00} & \\colorbox{gray!20}{1.00} & \\colorbox{red!20}{0.28} & \\colorbox{gray!20}{0.76} & \\colorbox{gray!20}{0.92} & \\colorbox{red!20}{0.88} & \\colorbox{gray!20}{0.96}  & 0(nan) & 0(nan) & 8(0.85) & 3(0.987) & 4(0.91) & 2 \\ \\\\\n",
      "\\small 3183.0 & \\colorbox{blue!20}{0.96} & - & \\colorbox{red!50}{0.88} & \\colorbox{blue!20}{0.52} & - & \\colorbox{blue!20}{0.80} & - & - & - & \\colorbox{red!50}{0.00} & \\colorbox{red!20}{0.44} & - & \\colorbox{blue!20}{0.48} & \\colorbox{red!20}{0.96} & \\colorbox{red!50}{0.80} & \\colorbox{red!50}{1.00} & \\colorbox{blue!20}{0.52}  & 4(0.67) & 0(nan) & 2(0.7) & 5(0.656) & 0(nan) & 6 \\ \\\\\n",
      "\\small 3402.0 & \\colorbox{red!20}{0.84} & \\colorbox{blue!20}{0.92} & - & \\colorbox{blue!20}{0.60} & \\colorbox{blue!20}{0.92} & \\colorbox{blue!20}{0.88} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.72} & \\colorbox{blue!20}{0.92} & \\colorbox{gray!20}{0.80} & \\colorbox{blue!20}{0.96} & \\colorbox{gray!20}{0.32} & \\colorbox{gray!20}{1.00} & \\colorbox{red!20}{0.64} & \\colorbox{red!20}{0.92}  & 0(nan) & 0(nan) & 6(0.853) & 7(0.886) & 3(0.707) & 1 \\ \\\\\n",
      "\\small 4752.0 & \\colorbox{blue!20}{0.92} & \\colorbox{blue!20}{0.52} & \\colorbox{red!20}{0.40} & \\colorbox{blue!20}{0.76} & \\colorbox{red!20}{0.96} & - & - & - & \\colorbox{red!20}{0.72} & \\colorbox{blue!20}{0.92} & \\colorbox{blue!50}{0.68} & \\colorbox{red!20}{0.92} & \\colorbox{blue!50}{0.96} & \\colorbox{blue!50}{0.96} & \\colorbox{red!20}{0.96} & - & \\colorbox{red!20}{0.76}  & 0(nan) & 3(0.867) & 6(0.787) & 4(0.78) & 0(nan) & 4 \\ \\\\\n",
      "\\small 6188.0 & \\colorbox{red!20}{0.84} & \\colorbox{blue!20}{0.84} & - & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.68} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.76} & \\colorbox{red!20}{0.60} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.72} & \\colorbox{gray!20}{0.36} & \\colorbox{gray!20}{0.84} & \\colorbox{red!20}{0.64} & \\colorbox{red!20}{0.84}  & 0(nan) & 0(nan) & 8(0.795) & 6(0.907) & 2(0.6) & 1 \\ \\\\\n",
      "\\small 6216.0 & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{0.92} & - & \\colorbox{blue!50}{0.08} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.88} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.92} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{1.00} & \\colorbox{gray!20}{0.76} & \\colorbox{blue!20}{0.64} & \\colorbox{red!20}{0.28} & \\colorbox{gray!20}{0.92} & \\colorbox{red!20}{1.00} & \\colorbox{gray!20}{0.76}  & 0(nan) & 1(0.08) & 7(0.863) & 5(0.88) & 3(0.813) & 1 \\ \\\\\n",
      "\\small 6619.0 & - & \\colorbox{blue!20}{0.48} & - & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{0.84} & \\colorbox{blue!20}{0.88} & \\colorbox{red!20}{0.84} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.88} & - & \\colorbox{red!20}{0.40} & \\colorbox{gray!20}{0.88} & \\colorbox{red!20}{0.60} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.12} & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{0.60}  & 0(nan) & 0(nan) & 8(0.75) & 5(0.672) & 1(0.88) & 3 \\ \\\\\n",
      "\\small 6884.0 & - & \\colorbox{blue!20}{0.52} & - & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.84} & - & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.72} & - & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{0.68} & \\colorbox{red!20}{0.68}  & 0(nan) & 0(nan) & 5(0.784) & 8(0.9) & 0(nan) & 4 \\ \\\\\n",
      "\\small 7502.0 & \\colorbox{blue!20}{0.80} & \\colorbox{blue!20}{0.92} & - & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.96} & - & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.92} & \\colorbox{gray!20}{0.88} & \\colorbox{blue!20}{1.00} & \\colorbox{gray!20}{0.24} & \\colorbox{gray!20}{0.96} & \\colorbox{red!20}{0.88} & \\colorbox{gray!20}{0.72}  & 0(nan) & 0(nan) & 5(0.944) & 6(0.933) & 4(0.7) & 2 \\ \\\\\n",
      "\\small 8387.0 & - & - & \\colorbox{blue!20}{0.40} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{1.00} & - & \\colorbox{red!20}{0.80} & \\colorbox{blue!20}{1.00} & - & \\colorbox{red!20}{0.32} & \\colorbox{blue!20}{0.44} & \\colorbox{blue!20}{0.76} & \\colorbox{red!20}{0.36} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.76}  & 0(nan) & 0(nan) & 8(0.76) & 5(0.712) & 0(nan) & 4 \\ \\\\\n",
      "\\small 10096.0 & - & - & - & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{0.64} & - & \\colorbox{blue!20}{0.92} & - & - & - & \\colorbox{blue!20}{0.76} & \\colorbox{gray!20}{0.48} & \\colorbox{red!20}{0.84} & - & \\colorbox{red!20}{0.84}  & 0(nan) & 0(nan) & 6(0.86) & 2(0.84) & 1(0.48) & 8 \\ \\\\\n",
      "\\small 10454.0 & \\colorbox{red!20}{0.84} & \\colorbox{blue!20}{0.64} & - & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.88} & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{0.88} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.80} & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.96} & \\colorbox{gray!20}{0.88} & \\colorbox{blue!20}{1.00} & \\colorbox{gray!20}{0.28} & \\colorbox{gray!20}{0.96} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.72}  & 0(nan) & 0(nan) & 6(0.847) & 7(0.92) & 3(0.707) & 1 \\ \\\\\n",
      "\\small 10605.0 & \\colorbox{blue!20}{0.80} & \\colorbox{blue!20}{0.84} & - & \\colorbox{blue!20}{0.68} & \\colorbox{blue!20}{0.76} & \\colorbox{red!20}{0.36} & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.72} & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.92} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.68} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.84}  & 0(nan) & 0(nan) & 7(0.794) & 9(0.876) & 0(nan) & 1 \\ \\\\\n",
      "\\small 11712.0 & \\colorbox{red!20}{0.76} & \\colorbox{red!20}{0.96} & - & \\colorbox{gray!20}{0.72} & \\colorbox{blue!20}{0.56} & \\colorbox{blue!20}{0.68} & \\colorbox{red!20}{0.92} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.68} & \\colorbox{red!20}{0.60} & \\colorbox{blue!20}{0.96} & \\colorbox{gray!20}{0.96} & \\colorbox{blue!20}{1.00} & \\colorbox{gray!20}{0.40} & \\colorbox{red!20}{0.52} & \\colorbox{red!20}{0.84} & \\colorbox{red!20}{0.64}  & 0(nan) & 0(nan) & 8(0.74) & 5(0.84) & 3(0.693) & 1 \\ \\\\\n",
      "\\small 12703.0 & \\colorbox{red!20}{0.64} & \\colorbox{red!20}{1.00} & - & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.84} & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.88} & \\colorbox{red!20}{1.00} & \\colorbox{gray!20}{0.76} & \\colorbox{blue!20}{0.72} & \\colorbox{red!20}{0.36} & \\colorbox{gray!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.76}  & 0(nan) & 0(nan) & 8(0.83) & 6(0.9) & 2(0.86) & 1 \\ \\\\\n",
      "\\small 14049.0 & - & \\colorbox{blue!20}{0.52} & - & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{0.68} & - & \\colorbox{blue!50}{0.60} & \\colorbox{red!20}{0.80} & \\colorbox{red!20}{0.92} & - & \\colorbox{blue!20}{0.84} & \\colorbox{red!20}{1.00} & - & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{0.52} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.84}  & 0(nan) & 1(0.6) & 6(0.86) & 5(0.776) & 0(nan) & 5 \\ \\\\\n",
      "\\small 14185.0 & - & \\colorbox{red!20}{0.64} & - & \\colorbox{red!20}{0.76} & \\colorbox{red!20}{1.00} & \\colorbox{blue!20}{0.48} & - & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.60} & \\colorbox{blue!20}{1.00} & \\colorbox{blue!20}{0.88} & \\colorbox{red!20}{0.88} & \\colorbox{blue!20}{0.96} & \\colorbox{red!20}{0.92} & \\colorbox{red!20}{0.84} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.44}  & 0(nan) & 0(nan) & 9(0.844) & 5(0.752) & 0(nan) & 3 \\ \\\\\n",
      "\\small 14351.0 & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{1.00} & - & \\colorbox{blue!20}{0.96} & \\colorbox{blue!20}{0.76} & \\colorbox{blue!20}{1.00} & \\colorbox{red!20}{0.96} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{1.00} & \\colorbox{red!20}{0.96} & \\colorbox{blue!20}{0.96} & \\colorbox{gray!20}{1.00} & \\colorbox{blue!20}{0.88} & \\colorbox{gray!20}{0.32} & \\colorbox{gray!20}{0.96} & \\colorbox{red!20}{0.88} & \\colorbox{gray!20}{0.80}  & 0(nan) & 0(nan) & 6(0.96) & 6(0.927) & 4(0.77) & 1 \\ \\\\\n",
      " \\midrule\n",
      " \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "}\n",
      "\\end{center}\n",
      "\\end{table*}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def get_latex_table(table1, table1_name):\n",
    "    latex_code = '\\\\begin{table*}[ht]\\n\\\\caption{Value steering using SAE features for the Gemma-2B-IT model. Expected stimulated values are highlighted in red, along with their actual success rate during testing. Expected suppressed values are marked in Purple. Maintained values are shown in gray. Light red indicates values that are expected to be at least not suppressed, while light purple represents values that are expected to be at least not stimulated. Blank cells correspond to uncontrollable values. The bottom of the table indicates the count of each of the six expected categories and their average success rates.}\\n\\\\label{table: sae-steering-gemma}\\n\\\\begin{center}\\n\\\\scalebox{0.5}{'\n",
    "    #latex_code = '\\\\begin{table}[ht]\\n\\\\caption{Value steering using SAE features for the Llama3-8B-IT model.}\\n\\\\label{table: sae-steering-llama}\\n\\\\begin{center}\\n'\n",
    "\n",
    "    latex_code += '\\\\begin{tabular}{c@{\\\\hspace{2pt}}' + 'c@{\\\\hspace{2pt}}' * (len(table1.columns) - 1) + 'c' + '}\\n\\\\toprule\\n'\n",
    "    #transfer table1.columns to a list of str\n",
    "\n",
    "\n",
    "    steering_features = list(map(str, map(int, table1.columns)))\n",
    "    latex_code += 'Value & ' + ' & '.join(['\\\\bf ' + tc for tc in steering_features]) + ' \\\\\\\\\\n\\\\hline\\n'\n",
    "    #\n",
    "\n",
    "    stimulated_dim_avg_success = {sf: [] for sf in steering_features}\n",
    "    stimulhalf_dim_avg_success = {sf: [] for sf in steering_features}\n",
    "    suppressed_dim_avg_success = {sf: [] for sf in steering_features}\n",
    "    supprehalf_dim_avg_success = {sf: [] for sf in steering_features}\n",
    "    maintained_dim_avg_success = {sf: [] for sf in steering_features}\n",
    "\n",
    "\n",
    "    uncontroll_dims = {sf: 0 for sf in steering_features}\n",
    "    stimulated_dims = {sf: 0 for sf in steering_features} \n",
    "    suppressed_dims = {sf: 0 for sf in steering_features}\n",
    "    stimulhalf_dims = {sf: 0 for sf in steering_features}\n",
    "    supprehalf_dims = {sf: 0 for sf in steering_features}\n",
    "    maintained_dims = {sf: 0 for sf in steering_features}\n",
    "\n",
    "\n",
    "    for index, row in table1.iterrows():\n",
    "        #if value's name (index) is too long, make its font smaller, all value names should be available in 3pt\n",
    "        if len(index) > 20:\n",
    "            latex_code += '\\\\tiny ' + index + ' & '\n",
    "        else:\n",
    "            latex_code += '\\\\small ' + index + ' & '\n",
    "\n",
    "        for value, sf in zip(row, steering_features):\n",
    "            if type(value) == str:\n",
    "                print(value)\n",
    "                value = value.split(',')\n",
    "                \n",
    "                if value[0] == 'STIMULATE':\n",
    "                    stimulated_dim_avg_success[sf].append(float(value[1]))\n",
    "                    stimulated_dims[sf] += 1\n",
    "                    #latex_code += '\\\\textcolor{red}{\\\\textbf{$\\\\uparrow$}}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    latex_code += '\\\\colorbox{red!50}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    #latex_code += f\"{float(value[1]):.2f}\" + ' & '\n",
    "                elif value[0] == 'NON_SUPPRESS':\n",
    "                    stimulhalf_dim_avg_success[sf].append(float(value[1]))\n",
    "                    stimulhalf_dims[sf] += 1\n",
    "                    #latex_code += '\\\\textcolor{magenta}{\\\\textbf{$\\\\nearrow$}}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    latex_code += '\\\\colorbox{red!20}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    #latex_code += f\"{float(value[1]):.2f}\" + ' & '\n",
    "                elif value[0] == 'SUPPRESS':\n",
    "                    suppressed_dim_avg_success[sf].append(float(value[1]))\n",
    "                    suppressed_dims[sf] += 1\n",
    "                    #latex_code += '\\\\textcolor{blue}{\\\\textbf{$\\\\downarrow$}}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    latex_code += '\\\\colorbox{blue!50}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    #latex_code += f\"{float(value[1]):.2f}\" + ' & '\n",
    "                elif value[0] == 'NON_STIMULATE':\n",
    "                    supprehalf_dim_avg_success[sf].append(float(value[1]))\n",
    "                    supprehalf_dims[sf] += 1\n",
    "                    #latex_code += '\\\\textcolor{cyan}{\\\\textbf{$\\\\searrow$}}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    latex_code += '\\\\colorbox{blue!20}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    #latex_code += f\"{float(value[1]):.2f}\" + ' & '\n",
    "                elif value[0] == 'MAINTAIN':\n",
    "                    maintained_dim_avg_success[sf].append(float(value[1]))\n",
    "                    maintained_dims[sf] += 1\n",
    "                    #latex_code += '\\\\textcolor{purple}{\\\\textbf{-}}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    latex_code += '\\\\colorbox{gray!20}' + ' ' + f\"{float(value[1]):.2f}\" + ' & '\n",
    "                    #latex_code += f\"{float(value[1]):.2f}\" + ' & '\n",
    "                else:\n",
    "                    raise ValueError('Invalid value')\n",
    "            else:\n",
    "                assert np.isnan(value)\n",
    "                uncontroll_dims[sf] += 1\n",
    "                #latex_code += '\\\\textcolor{gray}{-} & '\n",
    "                latex_code += f\"-\" + ' & '\n",
    "                #latex_code += '- & '\n",
    "        latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "    latex_code = latex_code + ' \\\\midrule\\n'\n",
    "\n",
    "    for sf in steering_features:\n",
    "        stimulated_dim_avg_success[sf] = np.mean(stimulated_dim_avg_success[sf])\n",
    "        stimulhalf_dim_avg_success[sf] = np.mean(stimulhalf_dim_avg_success[sf])\n",
    "        suppressed_dim_avg_success[sf] = np.mean(suppressed_dim_avg_success[sf])\n",
    "        supprehalf_dim_avg_success[sf] = np.mean(supprehalf_dim_avg_success[sf])\n",
    "        maintained_dim_avg_success[sf] = np.mean(maintained_dim_avg_success[sf])\n",
    "        \n",
    "    latex_code += '\\\\colorbox{red!50} STIMULATE & '\n",
    "    for sf in steering_features:\n",
    "        cellcontent = round(stimulated_dim_avg_success[sf],3)\n",
    "        latex_code += '\\\\textbf{' + str(stimulated_dims[sf]) + f'({cellcontent})' +'} & '\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "\n",
    "    latex_code += '\\\\colorbox{blue!50} SUPPRESSED & '\n",
    "    for sf in steering_features:\n",
    "        cellcontent = round(suppressed_dim_avg_success[sf],3)\n",
    "        latex_code += '\\\\textbf{' + str(suppressed_dims[sf]) + f'({cellcontent})' +'} & '\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "\n",
    "    latex_code += '\\\\colorbox{red!20} NON-SUPPRESSED & '\n",
    "    for sf in steering_features:\n",
    "        cellcontent = round(stimulhalf_dim_avg_success[sf],3)\n",
    "        latex_code += '\\\\textbf{' + str(stimulhalf_dims[sf]) + f'({cellcontent})' +'} & '\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "\n",
    "    latex_code +='\\\\colorbox{blue!20} NON-STIMULATED & '\n",
    "    for sf in steering_features:\n",
    "        cellcontent = round(supprehalf_dim_avg_success[sf],3)\n",
    "        latex_code += '\\\\textbf{' + str(supprehalf_dims[sf]) + f'({cellcontent})' +'} & '\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "\n",
    "    latex_code += '\\\\colorbox{gray!20} MAINTAINED & '\n",
    "    for sf in steering_features:\n",
    "        cellcontent = round(maintained_dim_avg_success[sf],3)\n",
    "        latex_code += '\\\\textbf{' + str(maintained_dims[sf]) + f'({cellcontent})' +'} & '\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "\n",
    "    latex_code += 'UNCONTROLLED & '\n",
    "    for sf in steering_features:\n",
    "        latex_code += '\\\\textbf{' + str(uncontroll_dims[sf]) +'} & '\n",
    "\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n\\\\bottomrule\\n'\n",
    "    latex_code += '\\\\end{tabular}\\n}\\n\\\\end{center}\\n\\\\end{table*}'\n",
    "    print(latex_code)\n",
    "    #write the latex code to a file\n",
    "    with open(table1_name+'.tex', 'w') as f:\n",
    "        f.write(latex_code)\n",
    "\n",
    "get_latex_table(table1_gemma, 'table1_gemma')\n",
    "\n",
    "#OK, nice job. Now let's make another form of the latex table. This time, the rows will be the steering features and the columns will be the value dimensions. \n",
    "#The cells will contain the success rate of steering the value dimension using the steering feature.\n",
    "#To avoid making the table too wide, the string of value dimensions will be rotated 90 degrees.\n",
    "#Let's begin\n",
    "def get_latex_table_rotate(table1, table1_name):\n",
    "    latex_code = '\\\\begin{table*}[ht]\\n\\\\caption{Value steering using SAE features for the Gemma-2B-IT model. Expected stimulated values are highlighted in red, along with their actual success rate during testing. Expected suppressed values are marked in Purple. Maintained values are shown in gray. Light red indicates values that are expected to be at least not suppressed, while light purple represents values that are expected to be at least not stimulated. Blank cells correspond to uncontrollable values. The bottom of the table indicates the count of each of the six expected categories and their average success rates.}\\n\\\\label{table: sae-steering-gemma}\\n\\\\begin{center}\\n\\\\scalebox{0.5}{'\n",
    "\n",
    "    latex_code += '\\\\begin{tabular}{' + 'c@{\\\\hspace{1.5pt}}|' * (len(table1.index) + 6) + 'c' + '}\\n\\\\toprule\\n'\n",
    "    #latex_code += '\\\\begin{tabular}{' + 'c|' * len(table1.index) + 'c' + '}\\n\\\\toprule\\n'\n",
    "    #transfer table1.columns to a list of str\n",
    "\n",
    "    value_dims = list(map(str, table1.index))\n",
    "    steering_features = table1.columns\n",
    "    latex_code += 'Value & ' + ' & '.join(['\\\\rotatebox{90}{\\\\bf ' + tc +'}' for tc in value_dims]) + ' &\\\\rotatebox{90} {\\\\bf STIMULATE} & \\\\rotatebox{90} {\\\\bf SUPPRESS} & \\\\rotatebox{90} {\\\\bf NON-SUPPRESS}& \\\\rotatebox{90} {\\\\bf NON-STIMULATE} & \\\\rotatebox{90} {\\\\bf MAINTAIN} & \\\\rotatebox{90} {\\\\bf UNCONTROLLED} \\\\\\\\\\n\\\\hline\\n'\n",
    "    \n",
    "\n",
    "\n",
    "    for sf in steering_features:\n",
    "        stimulated_dim_avg_success = []\n",
    "        stimulhalf_dim_avg_success = []\n",
    "        suppressed_dim_avg_success = []\n",
    "        supprehalf_dim_avg_success = []\n",
    "        maintained_dim_avg_success = []\n",
    "\n",
    "\n",
    "        uncontroll_dims = 0\n",
    "        stimulated_dims = 0\n",
    "        suppressed_dims = 0\n",
    "        stimulhalf_dims = 0\n",
    "        supprehalf_dims = 0\n",
    "        maintained_dims = 0\n",
    "\n",
    "        latex_code += '\\\\small ' + str(sf) + ' & '\n",
    "        for vd in value_dims:\n",
    "            value = table1.loc[vd, sf]\n",
    "            if type(value) == str:\n",
    "                value = value.split(',')\n",
    "                if value[0] == 'STIMULATE':\n",
    "                    stimulated_dim_avg_success.append(float(value[1]))\n",
    "                    stimulated_dims += 1\n",
    "                    latex_code += '\\\\colorbox{red!50}' + '{' + f\"{float(value[1]):.2f}\" + '} & '\n",
    "                elif value[0] == 'NON_SUPPRESS':\n",
    "                    stimulhalf_dim_avg_success.append(float(value[1]))\n",
    "                    stimulhalf_dims += 1\n",
    "                    latex_code += '\\\\colorbox{red!20}' + '{' + f\"{float(value[1]):.2f}\" + '} & '\n",
    "                elif value[0] == 'SUPPRESS':\n",
    "                    suppressed_dim_avg_success.append(float(value[1]))\n",
    "                    suppressed_dims += 1\n",
    "                    latex_code += '\\\\colorbox{blue!50}' + '{' + f\"{float(value[1]):.2f}\" + '} & '\n",
    "                elif value[0] == 'NON_STIMULATE':\n",
    "                    supprehalf_dim_avg_success.append(float(value[1]))\n",
    "                    supprehalf_dims += 1\n",
    "                    latex_code += '\\\\colorbox{blue!20}' + '{' + f\"{float(value[1]):.2f}\" + '} & '\n",
    "                elif value[0] == 'MAINTAIN':\n",
    "                    maintained_dim_avg_success.append(float(value[1]))\n",
    "                    maintained_dims += 1\n",
    "                    latex_code += '\\\\colorbox{gray!20}' + '{' + f\"{float(value[1]):.2f}\" + '} & '\n",
    "                else:\n",
    "                    raise ValueError('Invalid value')\n",
    "            else:\n",
    "                assert np.isnan(value)\n",
    "                uncontroll_dims += 1\n",
    "                latex_code += f\"-\" + ' & '\n",
    "        latex_code = latex_code[:-2] + ' & ' + str(stimulated_dims) + f'({round(np.mean(stimulated_dim_avg_success),3)})' + ' & ' + str(suppressed_dims) + f'({round(np.mean(suppressed_dim_avg_success),3)})' + ' & ' + str(stimulhalf_dims) + f'({round(np.mean(stimulhalf_dim_avg_success),3)})'  + ' & ' + str(supprehalf_dims) + f'({round(np.mean(supprehalf_dim_avg_success),3)})' + ' & ' + str(maintained_dims) + f'({round(np.mean(maintained_dim_avg_success),3)})' + ' & ' + str(uncontroll_dims) + ' \\\\\\\\\\n'\n",
    "\n",
    "        latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "    latex_code = latex_code + ' \\\\midrule\\n'\n",
    "    \n",
    "    latex_code = latex_code + ' \\\\\\\\\\n\\\\bottomrule\\n'\n",
    "\n",
    "\n",
    "\n",
    "    latex_code += '\\\\end{tabular}\\n}\\n\\\\end{center}\\n\\\\end{table*}'\n",
    "    print(latex_code)\n",
    "    #write the latex code to a file\n",
    "    with open(table1_name+'.tex', 'w') as f:\n",
    "        f.write(latex_code)\n",
    "    \n",
    "get_latex_table_rotate(table1_gemma, 'table1_gemma_rotate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2525, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4d20548bd249c9856e2325c0f35c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31869bfd8ff14eb2940652c8caa61ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10096.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26a74c4ce924d18ab276046d2963025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8387.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d712c4739640f3993cb9baf7ba3ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2221.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909f28dce54747ab9e1472f38f81fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1312.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d7c8bf6ccc452ba3e37ce789419b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7502.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f54be5546647ceab8b9088b136b7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14049.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50b2f118376a43e095396cc74b0f6976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3183.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7658ff2441e243d280ebfcb9d2487d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6619.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414da1d37cb941158ec1ec67fac8c2e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1341.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bfae3d38a94c9baf14351303bc6a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6884.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e5c926273a4ecea66ace05f81c940d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12703.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7977f9ef56ec4b9b96f18574254595b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11712.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a83459483d4abd8c9ec5ec10f3ed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14185.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf34b2eacf94d7f939dca70ec1175ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10454.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187ed282108445dcbb2dd9fac6edb721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6216.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b69c161d20e4306a51dee0eb99e9014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89582540fcec473494d391c44a7c2212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10605.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b91f92f73bd4dc9b9fed04b068ac362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6188.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4433170f26904c6da1a76b885d20c572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4752.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f9527f071246b784334dd762e306ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3402.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa887d8c51b4449a6e966a8e8091d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bfc5457dcac401597b04c037ca3bfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2019ea139545fda7dad5ae8691a802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14351.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b855e1a30174286b59da05c8d9ed7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2965.0\n",
      "(101, 17)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17c7debdb5946b4b075bc1cff30bedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_valid_d_columns_deprecated(answer_valuebench_features_csv):\n",
    "    data_csv = pd.read_csv(answer_valuebench_features_csv)\n",
    "    digits = [str(d) for d in range(10)]\n",
    "    d_columns = [d for d in data_csv.columns if d[0] in digits]\n",
    "    d_data = data_csv[d_columns]\n",
    "    stds = d_data.std()\n",
    "    avgs = d_data.mean()\n",
    "    std_avg = stds/avgs\n",
    "    #d_columns_valid = [d for d in d_columns if avgs[d] > 1]\n",
    "    d_columns_valid = d_columns\n",
    "    return d_columns_valid\n",
    "\n",
    "def deal_with_csv(data_csv, pdy_name, v_inference, v_showongraph, row_num, method='pc', dummy_steered_dim=False): \n",
    "    # data_csv = pd.read_csv(answer_valuebench_features_csv)\n",
    "    # v_columns_all = [v for v in data_csv.columns if (v not in ['player_name', 'steer_dim', 'stds']) and (not v.endswith(':scstd'))]\n",
    "    # if v_inference == 'ALL':\n",
    "    #     v_columns_inference = v_columns_all\n",
    "    # else:\n",
    "    #     for v in v_inference:\n",
    "    #         if v not in v_columns_all:\n",
    "    #             raise ValueError('Invalid v_inference')\n",
    "    #     v_columns_inference = v_inference\n",
    "\n",
    "    v_columns_inference = v_inference\n",
    "\n",
    "    if v_showongraph == 'ALL':\n",
    "        v_columns_showgraph = v_columns_inference\n",
    "    else:\n",
    "        for v in v_showongraph:\n",
    "            if v not in v_columns_inference:\n",
    "                raise ValueError('Invalid v_showongraph')\n",
    "        v_columns_showgraph = v_showongraph\n",
    "\n",
    "    if dummy_steered_dim:\n",
    "        steer_dim_dummies = pd.get_dummies(data_csv['steer_dim'], prefix='steer_dim') * 1\n",
    "        data = pd.concat([data_csv, steer_dim_dummies], axis=1)\n",
    "        v_columns_inference_total = v_columns_inference + list(steer_dim_dummies.columns) \n",
    "        v_columns_showgraph_total = v_columns_showgraph + list(steer_dim_dummies.columns)\n",
    "    else:\n",
    "        data = data_csv\n",
    "        v_columns_inference_total = v_columns_inference\n",
    "        v_columns_showgraph_total = v_columns_showgraph\n",
    "    \n",
    "    data = data[v_columns_inference_total].to_numpy()    \n",
    "    \n",
    "    if type(row_num) == int:\n",
    "        rows = np.random.choice(data.shape[0], row_num, replace=False)\n",
    "        data = data[rows]\n",
    "    else:\n",
    "        assert row_num == 'ALL'\n",
    "\n",
    "    if dummy_steered_dim:\n",
    "        edges_total = causal_inference(data, v_columns_inference_total, pdy_name, method, noise_augument=None, prior_source_set=list(steer_dim_dummies.columns))\n",
    "    else:\n",
    "        edges_total = causal_inference(data, v_columns_inference_total, pdy_name, method, noise_augument=10)\n",
    "    \n",
    "    edges_sfs = []\n",
    "    steer_dims = data_csv['steer_dim'].unique()\n",
    "    for steer_dim in steer_dims:\n",
    "        print(steer_dim)\n",
    "        if np.isnan(steer_dim):\n",
    "            data = data_csv[data_csv['steer_dim'].isnull()][v_columns_inference].to_numpy()\n",
    "        else:\n",
    "            data = data_csv[data_csv['steer_dim'] == steer_dim][v_columns_inference].to_numpy()\n",
    "        sfedge = causal_inference(data, v_columns_inference, pdy_name.replace('.png', f'_{steer_dim}.png'), method, noise_augument=10)\n",
    "        edges_sfs.append(sfedge)\n",
    "\n",
    "    return edges_total, edges_sfs\n",
    "\n",
    "def causal_inference(data, ci_dimensions, pdy_name, method, noise_augument=None, prior_source_set=None):\n",
    "    print(data.shape)\n",
    "    \n",
    "    #0 is the mean of the normal distribution you are choosing from, and 0.01 is the standard deviation of this distribution.\n",
    "    #scale the data for several times by adding noise\n",
    "    if noise_augument:\n",
    "        data = np.tile(data, (noise_augument, 1))\n",
    "        noise = np.random.normal(0, 0.00001, data.shape)\n",
    "        data = data + noise\n",
    "\n",
    "    if method == 'pc':\n",
    "        #g = pc(data, 0.0005, uc_rule=0, rule_priority=2, node_names=ci_dimensions)\n",
    "        g = pc(data, 0.0005, node_names=ci_dimensions)\n",
    "        \n",
    "        if prior_source_set:\n",
    "            bk = BackgroundKnowledge()\n",
    "            nodes = g.G.get_nodes()\n",
    "            for node1 in nodes:\n",
    "                for node2 in nodes:\n",
    "                    if node1.name in prior_source_set and node2.name in prior_source_set and node1.name != node2.name:\n",
    "                        bk = bk.add_forbidden_by_node(node1, node2)\n",
    "            #g = pc(data, 0.0005, uc_rule=0, rule_priority=2, node_names=ci_dimensions, background_knowledge=bk)\n",
    "            g = pc(data, 0.0005, node_names=ci_dimensions, background_knowledge=bk)\n",
    "            \n",
    "        graph = g.G\n",
    "\n",
    "        edges = []\n",
    "        for n1 in range(len(graph.nodes)):\n",
    "            assert graph.nodes[n1].name == ci_dimensions[n1]\n",
    "            for n2 in range(n1+1, len(graph.nodes)):\n",
    "                # if n1 == n2:\n",
    "                #     continue\n",
    "                if graph.graph[n1][n2] == -1 and graph.graph[n2][n1] == 1:\n",
    "                    edges.append([graph.nodes[n1].name, graph.nodes[n2].name, 1, 'single-arrow'])\n",
    "                elif graph.graph[n1][n2] == 1 and graph.graph[n2][n1] == -1:\n",
    "                    edges.append([graph.nodes[n2].name, graph.nodes[n1].name, 1, 'single-arrow']) \n",
    "                elif graph.graph[n1][n2] == -1 and graph.graph[n2][n1] == -1:\n",
    "                    edges.append([graph.nodes[n1].name, graph.nodes[n2].name, 1, 'no-arrow'])\n",
    "                elif graph.graph[n1][n2] == 1 and graph.graph[n2][n1] == 1:\n",
    "                    edges.append([graph.nodes[n1].name, graph.nodes[n2].name, 1, 'double-arrow'])\n",
    "                else:\n",
    "                    if not (graph.graph[n1][n2] == 0 and graph.graph[n2][n1] == 0):\n",
    "                        raise ValueError('Invalid edge')\n",
    "    else:\n",
    "        raise ValueError('Invalid method')\n",
    "    \n",
    "    columns_concerned_vis = [label.replace(':','-') for label in ci_dimensions]\n",
    "    pdy = GraphUtils.to_pydot(graph, labels=columns_concerned_vis)\n",
    "    pdy.write_png(pdy_name)\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "#data_csv = data_csv[data_csv['player_name'].notnull()]\n",
    "\n",
    "v_inference_gemma = [v for v in data_csv_gemma_train.columns if (v not in ['player_name', 'steer_dim', 'stds', 'scstds']) and (not v.endswith(':scstd'))]\n",
    "# v_inference_llama = [v for v in data_csv_llama_train.columns if (v not in ['player_name', 'steer_dim', 'stds', 'scstds']) and (not v.endswith(':scstd'))]\n",
    "# assert v_inference_gemma == v_inference_llama\n",
    "v_inference = v_inference_gemma\n",
    "\n",
    "#v_inference = ['Affiliation', 'Assertiveness', 'Behavioral Inhibition System', 'Breadth of Interest', 'Complexity', 'Dependence', 'Depth', 'Emotional Expression', 'Emotional Processing', 'Empathy', 'Extraversion', 'Imagination', 'Nurturance', 'Perspective Taking', 'Social Withdrawal', 'Positive Expressivity', 'Preference for Order and Structure', 'Privacy', 'Psychosocial flourishing', 'Reflection']\n",
    "#v_inference = ['Affiliation', 'Assertiveness', 'Behavioral Inhibition System', 'Breadth of Interest', 'Complexity', 'Dependence', 'Depth', 'Emotional Expression', 'Emotional Processing', 'Empathy', 'Extraversion', ]\n",
    "\n",
    "if os.path.exists('value_causal_graph_gemma'):\n",
    "    shutil.rmtree('value_causal_graph_gemma')\n",
    "os.makedirs('value_causal_graph_gemma', exist_ok=True)\n",
    "edges_gemma_total, edges_gemma_sfs = deal_with_csv(data_csv_gemma_train, \"value_causal_graph_gemma/total.png\", v_inference, 'ALL', 'ALL', 'pc', False)\n",
    "\n",
    "# if os.path.exists('value_causal_graph_llama'):\n",
    "#     shutil.rmtree('value_causal_graph_llama')\n",
    "# os.makedirs('value_causal_graph_llama', exist_ok=True)\n",
    "# edges_llama_total, edges_llama_sfs = deal_with_csv(data_csv_llama_train, \"value_causal_graph_llama/total.png\", v_inference, 'ALL', 'ALL', 'pc', False)\n",
    "\n",
    "edges_standard_json = json.load(open('value_graph_smallset_triplets.json'))\n",
    "edges_standard = []\n",
    "for edge in edges_standard_json:\n",
    "    if edge[1] == '-->':\n",
    "        edges_standard.append([edge[0], edge[2], 1, 'single-arrow'])\n",
    "    elif edge[1] == 'o--o':\n",
    "        edges_standard.append([edge[0], edge[2], 1, 'double-arrow'])\n",
    "    else:\n",
    "        raise ValueError('Invalid edge')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achievement\n",
      "Related: nan 0\n",
      "Unrelated: 0.19507038926681783 16\n",
      "----------------------\n",
      "Aesthetic\n",
      "Related: nan 0\n",
      "Unrelated: 0.19354095804988666 16\n",
      "----------------------\n",
      "Anxiety Disorder\n",
      "Related: nan 0\n",
      "Unrelated: 0.1998253105590062 16\n",
      "----------------------\n",
      "Breadth of Interest\n",
      "Related: 0.3194444444444444 1\n",
      "Unrelated: 0.21679894179894182 15\n",
      "----------------------\n",
      "Economic\n",
      "Related: nan 0\n",
      "Unrelated: 0.19168709150326796 16\n",
      "----------------------\n",
      "Empathy\n",
      "Related: 0.19275362318840578 5\n",
      "Unrelated: 0.2179402722880983 11\n",
      "----------------------\n",
      "Organization\n",
      "Related: 0.25 2\n",
      "Unrelated: 0.20153061224489796 14\n",
      "----------------------\n",
      "Political\n",
      "Related: nan 0\n",
      "Unrelated: 0.1837797619047619 16\n",
      "----------------------\n",
      "Positive coping\n",
      "Related: 0.2175925925925926 4\n",
      "Unrelated: 0.18130878894767785 12\n",
      "----------------------\n",
      "Religious\n",
      "Related: 0.37267080745341624 1\n",
      "Unrelated: 0.1845525649873476 15\n",
      "----------------------\n",
      "Resilience\n",
      "Related: 0.2626262626262626 3\n",
      "Unrelated: 0.18581418581418582 13\n",
      "----------------------\n",
      "Social\n",
      "Related: 0.19696969696969696 1\n",
      "Unrelated: 0.19903799903799904 15\n",
      "----------------------\n",
      "Social Complexity\n",
      "Related: 0.2326839826839827 6\n",
      "Unrelated: 0.20122655122655125 10\n",
      "----------------------\n",
      "Social Cynicism\n",
      "Related: 0.1 5\n",
      "Unrelated: 0.22186147186147187 11\n",
      "----------------------\n",
      "Theoretical\n",
      "Related: 0.27777777777777773 3\n",
      "Unrelated: 0.17063492063492064 13\n",
      "----------------------\n",
      "Uncertainty Avoidance\n",
      "Related: 0.2753212396069539 7\n",
      "Unrelated: 0.14244072114442485 9\n",
      "----------------------\n",
      "Understanding\n",
      "Related: 0.31666666666666665 2\n",
      "Unrelated: 0.1680272108843537 14\n",
      "----------------------\n",
      "Achievement\n",
      "Related: nan 0\n",
      "Unrelated: 0.19507038926681783 16\n",
      "----------------------\n",
      "Aesthetic\n",
      "Related: nan 0\n",
      "Unrelated: 0.19354095804988666 16\n",
      "----------------------\n",
      "Anxiety Disorder\n",
      "Related: nan 0\n",
      "Unrelated: 0.1998253105590062 16\n",
      "----------------------\n",
      "Breadth of Interest\n",
      "Related: nan 0\n",
      "Unrelated: 0.22321428571428573 16\n",
      "----------------------\n",
      "Economic\n",
      "Related: nan 0\n",
      "Unrelated: 0.19168709150326796 16\n",
      "----------------------\n",
      "Empathy\n",
      "Related: nan 0\n",
      "Unrelated: 0.21006944444444445 16\n",
      "----------------------\n",
      "Organization\n",
      "Related: nan 0\n",
      "Unrelated: 0.20758928571428575 16\n",
      "----------------------\n",
      "Political\n",
      "Related: nan 0\n",
      "Unrelated: 0.1837797619047619 16\n",
      "----------------------\n",
      "Positive coping\n",
      "Related: nan 0\n",
      "Unrelated: 0.19037973985890652 16\n",
      "----------------------\n",
      "Religious\n",
      "Related: nan 0\n",
      "Unrelated: 0.19630995514147687 16\n",
      "----------------------\n",
      "Resilience\n",
      "Related: nan 0\n",
      "Unrelated: 0.2002164502164502 16\n",
      "----------------------\n",
      "Social\n",
      "Related: nan 0\n",
      "Unrelated: 0.19890873015873017 16\n",
      "----------------------\n",
      "Social Complexity\n",
      "Related: nan 0\n",
      "Unrelated: 0.21302308802308803 16\n",
      "----------------------\n",
      "Social Cynicism\n",
      "Related: nan 0\n",
      "Unrelated: 0.18377976190476192 16\n",
      "----------------------\n",
      "Theoretical\n",
      "Related: nan 0\n",
      "Unrelated: 0.19072420634920634 16\n",
      "----------------------\n",
      "Uncertainty Avoidance\n",
      "Related: nan 0\n",
      "Unrelated: 0.2005759479717813 16\n",
      "----------------------\n",
      "Understanding\n",
      "Related: 0.07777777777777778 2\n",
      "Unrelated: 0.20215419501133783 14\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_206495/580800275.py:120: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data_gemma_nosteer = data_csv_gemma_test[data_csv_gemma_test['steer_dim'].isnull()][data_csv_gemma_test['player_name'].notnull()]\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/fringsoo/Desktop/all_projs/proj_concordia/SAELens/.venv/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def check_zero_double_arrow(edges):\n",
    "    double_arrow_edges = [edge for edge in edges if edge[3] == 'double-arrow']\n",
    "    zero_arrow_edges = [edge for edge in edges if edge[3] == 'no-arrow']\n",
    "    if double_arrow_edges:\n",
    "        raise ValueError('Double arrow:', double_arrow_edges)\n",
    "    if zero_arrow_edges:\n",
    "        raise ValueError('Zero arrow:', zero_arrow_edges)\n",
    "\n",
    "def dealwith_zero_double_duplicated_arrow(edges):\n",
    "    double_arrow_edges = [edge for edge in edges if edge[3] == 'double-arrow']\n",
    "    zero_arrow_edges = [edge for edge in edges if edge[3] == 'no-arrow']\n",
    "    print('Double arrow:', double_arrow_edges)\n",
    "    print('Zero arrow:', zero_arrow_edges)\n",
    "    print('Dealwith zero and double arrow edges')\n",
    "    print('----------------------')\n",
    "    \n",
    "    new_edges = []\n",
    "    for edge in edges:\n",
    "        if edge[3] == 'double-arrow' or edge[3] == 'no-arrow':\n",
    "            if [edge[0], edge[1], edge[2], 'single-arrow'] not in new_edges:\n",
    "                new_edges.append([edge[0], edge[1], edge[2], 'single-arrow'])\n",
    "            if [edge[1], edge[0], edge[2], 'single-arrow'] not in new_edges:\n",
    "                new_edges.append([edge[1], edge[0], edge[2], 'single-arrow'])\n",
    "        else:\n",
    "            if edge not in new_edges:\n",
    "                new_edges.append(edge)\n",
    "    return new_edges\n",
    "\n",
    "\n",
    "\n",
    "def check_dag(edges):\n",
    "    nxg = nx.DiGraph()\n",
    "    for edge in edges:\n",
    "        if edge[3] == 'single-arrow':\n",
    "            nxg.add_edge(edge[0], edge[1])\n",
    "    if not nx.is_directed_acyclic_graph(nxg):\n",
    "        cycles = list(nx.simple_cycles(nxg))\n",
    "        raise ValueError('Cycle:', cycles)\n",
    "\n",
    "def get_all_subsequent_nodes(edges, node):\n",
    "    #check_zero_double_arrow(edges)\n",
    "\n",
    "    subsequent_nodes = set()\n",
    "    subsequent_nodes.add(node)\n",
    "    while True:\n",
    "        subsequent_nodes_len = len(subsequent_nodes)\n",
    "        for edge in edges:\n",
    "            if edge[0] in subsequent_nodes:\n",
    "                subsequent_nodes.add(edge[1])\n",
    "        if len(subsequent_nodes) == subsequent_nodes_len:\n",
    "            break\n",
    "    subsequent_nodes.remove(node)\n",
    "    return subsequent_nodes\n",
    "\n",
    "def write_table2(edges, data_scorechange, mean_scorechange_related, num_related, mean_scorechange_unrelated, num_unrelated):\n",
    "    for column in data_scorechange.columns:\n",
    "        print(column)\n",
    "        #related_columns_real1 = data_scorechange[data_scorechange[column] > 0].mean().abs().sort_values()\n",
    "        #related_columns_real2 = data_scorechange[data_scorechange[column] < -0].mean().abs().sort_values()\n",
    "        related_columns_real = data_scorechange[data_scorechange[column] != 0].abs().mean().sort_values()\n",
    "        related_columns_ideal = get_all_subsequent_nodes(edges, column)\n",
    "\n",
    "        related_scabs = []\n",
    "        unrelated_scabs = []\n",
    "        for related_column in related_columns_real.index:\n",
    "            if related_column in related_columns_ideal:\n",
    "                related_scabs.append(related_columns_real[related_column])\n",
    "            elif related_column != column:\n",
    "                unrelated_scabs.append(related_columns_real[related_column])\n",
    "            else:\n",
    "                assert related_column == column\n",
    "        #     print(related_column, related_columns_real[related_column], related_column in related_columns_ideal)\n",
    "        # print('~~~')\n",
    "        \n",
    "        print('Related:', np.mean([vdsc for vdsc in related_scabs if not np.isnan(vdsc)]), len(related_scabs))\n",
    "        print('Unrelated:', np.mean([vdsc for vdsc in unrelated_scabs if not np.isnan(vdsc)]), len(unrelated_scabs))\n",
    "        pd_result_table2.loc[mean_scorechange_related, column] = np.mean([vdsc for vdsc in related_scabs if not np.isnan(vdsc)])\n",
    "        pd_result_table2.loc[num_related, column] = len(related_scabs)\n",
    "        pd_result_table2.loc[mean_scorechange_unrelated, column] = np.mean([vdsc for vdsc in unrelated_scabs if not np.isnan(vdsc)])\n",
    "        pd_result_table2.loc[num_unrelated, column] = len(unrelated_scabs)\n",
    "        print('----------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd_result_table2 = pd.DataFrame(columns=v_inference)\n",
    "\n",
    "# edges_standard = dealwith_zero_double_arrow(edges_standard)\n",
    "edges_standard = [\n",
    "    ['Emotional Processing', 'Emotional Expression', 1, 'single-arrow'],\n",
    "    ['Emotional Processing', 'Psychosocial Flourishing', 1, 'single-arrow'],\n",
    "    ['Perspective Taking', 'Sympathy', 1, 'single-arrow'],\n",
    "    ['Perspective Taking', 'Empathy', 1, 'double-arrow'],\n",
    "    ['Perspective Taking', 'Nurturance', 1, 'double-arrow'],\n",
    "    ['Sociability', 'Extraversion', 1, 'double-arrow'],\n",
    "    ['Sociability', 'Warmth', 1, 'double-arrow'],\n",
    "    ['Sociability', 'Positive Expressivity', 1, 'double-arrow'],\n",
    "    ['Dependence', 'Nurturance', 1, 'single-arrow'],\n",
    "    ['Psychosocial Flourishing', 'Satisfaction with life', 1, 'single-arrow'],\n",
    "    ['Psychosocial Flourishing', 'Nurturance', 1, 'single-arrow'],\n",
    "    ['Extraversion', 'Positive Expressivity', 1, 'single-arrow'],\n",
    "    ['Extraversion', 'Social Confidence', 1, 'single-arrow'],\n",
    "    ['Extraversion', 'Social', 1, 'double-arrow'],\n",
    "    ['Affiliation', 'Empathy', 1, 'double-arrow'],\n",
    "    ['Affiliation', 'Social', 1, 'double-arrow'],\n",
    "    ['Understanding', 'Empathy', 1, 'double-arrow'],\n",
    "    ['Understanding', 'Reflection', 1, 'double-arrow'],\n",
    "    ['Understanding', 'Depth', 1, 'single-arrow'],\n",
    "    ['Understanding', 'Theoretical', 1, 'double-arrow'],\n",
    "    ['Sympathy', 'Nurturance', 1, 'single-arrow'],\n",
    "    ['Warmth', 'Empathy', 1, 'single-arrow'], \n",
    "    ['Warmth', 'Nurturance', 1, 'double-arrow'],\n",
    "    ['Warmth', 'Positive Expressivity', 1, 'single-arrow'],\n",
    "    ['Warmth', 'Social', 1, 'single-arrow'], \n",
    "    ['Empathy', 'Tenderness', 1, 'double-arrow'],\n",
    "    ['Empathy', 'Nurturance', 1, 'double-arrow'], \n",
    "    ['Positive Expressivity', 'Social', 1, 'double-arrow'],\n",
    "]\n",
    "\n",
    "data_gemma_nosteer = data_csv_gemma_test[data_csv_gemma_test['steer_dim'].isnull()][data_csv_gemma_test['player_name'].notnull()]\n",
    "data_gemma_nosteer = data_gemma_nosteer[v_inference + ['player_name']]\n",
    "data_gemma_nosteer = data_gemma_nosteer.set_index('player_name')\n",
    "data_gemma_nosteer = data_gemma_nosteer.astype(float)\n",
    "data_gemma_scorechange = data_gemma_nosteer - data_gemma_nosteer.iloc[0]\n",
    "\n",
    "edges_gemma_sfs0 = edges_gemma_sfs[0]\n",
    "#edges_gemma_sfs0 = dealwith_zero_double_arrow(edges_gemma_sfs[0])\n",
    "# for end_node in ['Affiliation', 'Breadth of Interest', 'Dependence']:#  'Behavioral Inhibition System'  'Nurturance'\n",
    "#     for start_node in ['Poise', 'Social Confidence', 'Preference for Order and Structure']:#[,  , 'Assertiveness']:\n",
    "#         edges_gemma_sfs0.append([end_node, start_node, 1, 'single-arrow'])\n",
    "\n",
    "write_table2(edges_gemma_sfs0, data_gemma_scorechange,  'mean_scorechange_related_ours_gemma', 'num_related_ours_gemma', 'mean_scorechange_unrelated_ours_gemma', 'num_unrelated_ours_gemma')\n",
    "write_table2(edges_standard, data_gemma_scorechange, 'mean_scorechange_related_standard_gemma', 'num_related_standard_gemma', 'mean_scorechange_unrelated_standard_gemma', 'num_unrelated_standard_gemma')\n",
    "\n",
    "\n",
    "# data_llama_nosteer = data_csv_llama_test[data_csv_llama_test['steer_dim'].isnull()][data_csv_llama_test['player_name'].notnull()]\n",
    "# data_llama_nosteer = data_llama_nosteer[v_inference + ['player_name']]\n",
    "# data_llama_nosteer = data_llama_nosteer.set_index('player_name')\n",
    "# data_llama_nosteer = data_llama_nosteer.astype(float)\n",
    "# data_llama_scorechange = data_llama_nosteer - data_llama_nosteer.iloc[0]\n",
    "\n",
    "# #edges_llama_sfs0 = dealwith_zero_double_arrow(edges_llama_sfs[0])\n",
    "# edges_llama_sfs0 = edges_llama_sfs[0]\n",
    "# write_table2(edges_llama_sfs0, data_llama_scorechange,  'mean_scorechange_related_ours_llama', 'num_related_ours_llama', 'mean_scorechange_unrelated_ours_llama', 'num_unrelated_ours_llama')\n",
    "# write_table2(edges_standard, data_llama_scorechange, 'mean_scorechange_related_standard_llama', 'num_related_standard_llama', 'mean_scorechange_unrelated_standard_llama', 'num_unrelated_standard_llama')\n",
    "\n",
    "pd_result_table2.to_csv('table2.csv')\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\caption{The mean of the score change of related values, the number of related values, the mean of the score change of unrelated values, and the number of unrelated values.}\n",
      "\\label{table: scorechange}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{c@{\\hspace{2pt}}|c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}|c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}c@{\\hspace{2pt}}}\n",
      "\\toprule\n",
      "Value & \\multicolumn{4}{c|}{\\bf \\small Gemma-2B-IT} & \\multicolumn{4}{c}{\\bf \\small Llama3-8B-IT}\\\\\n",
      "\\hline\n",
      "Dimensions & \\multicolumn{2}{c|}{\\bf \\tiny Our causal graph} & \\multicolumn{2}{c|}{\\bf \\tiny Our causal graph} & \\multicolumn{2}{c|}{\\bf \\tiny Our causal graph} & \\multicolumn{2}{c}{\\bf \\tiny Our causal graph}  \\\\\n",
      "\\hline\n",
      "Score change & \\multicolumn{1}{c}{\\bf \\tiny Expected} & \\multicolumn{1}{c|}{\\bf \\tiny Unexpected} & \\multicolumn{1}{c}{\\bf \\tiny Expected} & \\multicolumn{1}{c|}{\\bf \\tiny Unexpected} & \\multicolumn{1}{c}{\\bf \\tiny Expected} & \\multicolumn{1}{c|}{\\bf \\tiny Unexpected} & \\multicolumn{1}{c}{\\bf \\tiny Expected} & \\multicolumn{1}{c}{\\bf \\tiny Unexpected}\\\\\n",
      "\\hline\n",
      "\\small Achievement & nan & 0.2 & nan & 0.2  \\\\\n",
      "\\small Aesthetic & nan & 0.19 & nan & 0.19  \\\\\n",
      "\\small Anxiety Disorder & nan & 0.2 & nan & 0.2  \\\\\n",
      "\\small Breadth of Interest & 0.32 & 0.22 & nan & 0.22  \\\\\n",
      "\\small Economic & nan & 0.19 & nan & 0.19  \\\\\n",
      "\\small Empathy & 0.19 & 0.22 & nan & 0.21  \\\\\n",
      "\\small Organization & 0.25 & 0.2 & nan & 0.21  \\\\\n",
      "\\small Political & nan & 0.18 & nan & 0.18  \\\\\n",
      "\\small Positive coping & 0.22 & 0.18 & nan & 0.19  \\\\\n",
      "\\small Religious & 0.37 & 0.18 & nan & 0.2  \\\\\n",
      "\\small Resilience & 0.26 & 0.19 & nan & 0.2  \\\\\n",
      "\\small Social & 0.2 & 0.2 & nan & 0.2  \\\\\n",
      "\\small Social Complexity & 0.23 & 0.2 & nan & 0.21  \\\\\n",
      "\\small Social Cynicism & 0.1 & 0.22 & nan & 0.18  \\\\\n",
      "\\small Theoretical & 0.28 & 0.17 & nan & 0.19  \\\\\n",
      "\\small Uncertainty Avoidance & 0.28 & 0.14 & nan & 0.2  \\\\\n",
      "\\small Understanding & 0.32 & 0.17 & 0.08 & 0.2  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "#print the table2 in latex\n",
    "#rows are for each values dimensions\n",
    "#columns are in form num_related_ours(mean_scorechange_related_ours), num_unrelated_ours(mean_scorechange_unrelated_ours), num_related_standard(mean_scorechange_related_standard), num_unrelated_standard(mean_scorechange_unrelated_standard)\n",
    "#the values are the number of related values, the mean of the score change of related values, the number of unrelated values, the mean of the score change of unrelated values\n",
    "#the values are rounded to 3 decimal places\n",
    "#the values are in the form number(mean)\n",
    "#the values are in the form of number(mean)\n",
    "pd_result_table2 = pd.read_csv('table2.csv', index_col=0)\n",
    "latex_code = '\\\\begin{table}[ht]\\n\\\\caption{The mean of the score change of related values, the number of related values, the mean of the score change of unrelated values, and the number of unrelated values.}\\n\\\\label{table: scorechange}\\n\\\\begin{center}\\n'\n",
    "#latex_code += '\\\\begin{tabular}{c@{\\\\hspace{2pt}}' + 'c@{\\\\hspace{2pt}}' * (len(pd_result_table2.columns) - 1) + 'c' + '}\\n\\\\toprule\\n'\n",
    "latex_code += '\\\\begin{tabular}{c@{\\\\hspace{2pt}}|' + 'c@{\\\\hspace{2pt}}' * 4 +'|' + 'c@{\\\\hspace{2pt}}' * 4 + '}\\n\\\\toprule\\n'\n",
    "latex_code += 'Value & \\\\multicolumn{4}{c|}{\\\\bf \\\\small Gemma-2B-IT} & \\\\multicolumn{4}{c}{\\\\bf \\\\small Llama3-8B-IT}\\\\\\\\\\n\\\\hline\\n'\n",
    "latex_code += 'Dimensions & \\\\multicolumn{2}{c|}{\\\\bf \\\\tiny Our causal graph} & \\\\multicolumn{2}{c|}{\\\\bf \\\\tiny Our causal graph} & \\\\multicolumn{2}{c|}{\\\\bf \\\\tiny Our causal graph} & \\\\multicolumn{2}{c}{\\\\bf \\\\tiny Our causal graph}  \\\\\\\\\\n\\\\hline\\n'\n",
    "latex_code += 'Score change & \\\\multicolumn{1}{c}{\\\\bf \\\\tiny Expected} & \\\\multicolumn{1}{c|}{\\\\bf \\\\tiny Unexpected} & \\\\multicolumn{1}{c}{\\\\bf \\\\tiny Expected} & \\\\multicolumn{1}{c|}{\\\\bf \\\\tiny Unexpected} & \\\\multicolumn{1}{c}{\\\\bf \\\\tiny Expected} & \\\\multicolumn{1}{c|}{\\\\bf \\\\tiny Unexpected} & \\\\multicolumn{1}{c}{\\\\bf \\\\tiny Expected} & \\\\multicolumn{1}{c}{\\\\bf \\\\tiny Unexpected}\\\\\\\\\\n\\\\hline\\n'\n",
    "#each row in latex is a column in the dataframe\n",
    "for column in pd_result_table2.columns:\n",
    "    latex_code += '\\\\small ' + column + ' & '\n",
    "    for index in pd_result_table2.index:\n",
    "        if index.startswith('mean'):\n",
    "            latex_code += str(round(pd_result_table2.loc[index, column], 2)) + ' & '\n",
    "\n",
    "    latex_code = latex_code[:-2] + ' \\\\\\\\\\n'\n",
    "latex_code += '\\\\bottomrule\\n\\\\end{tabular}\\n\\\\end{center}\\n\\\\end{table}'\n",
    "print(latex_code)\n",
    "#write the latex code to a file\n",
    "with open('table2.tex', 'w') as f:\n",
    "    f.write(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#steer_dims = ['nan', 1312, 1341, 2221, 3183, 6619, 7502, 8387, 10096, 14049]\n",
    "\n",
    "nodes = {}\n",
    "for entity in v_inference:\n",
    "    nodes[entity] = os.path.join('valuebench','value_questions_' + entity + '.html'),\n",
    "# for feature in data_csv.['steer_dim'].unique()[1:]:\n",
    "#     nodes[feature] = 'https://www.neuronpedia.org/' + sae.cfg.model_name +'/' + str(sae.cfg.hook_layer) + '-res-jb/' + str(feature)\n",
    "\n",
    "edges = {\n",
    "    'gemma': edges_gemma_sfs0,\n",
    "    #'llama': edges_llama_sfs0,\n",
    "    'standard': edges_standard\n",
    "}\n",
    "\n",
    "json_object = {\n",
    "    'nodes': nodes,\n",
    "    'edges': edges\n",
    "    }\n",
    "\n",
    "json.dump(json_object, open('data1.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
